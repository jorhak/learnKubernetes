* 
* ==> Audit <==
* |-----------|-----------------------|----------|------|---------|---------------------|---------------------|
|  Command  |         Args          | Profile  | User | Version |     Start Time      |      End Time       |
|-----------|-----------------------|----------|------|---------|---------------------|---------------------|
| stop      |                       | minikube | jon  | v1.32.0 | 18 Apr 24 10:34 -04 | 18 Apr 24 10:34 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 18 Apr 24 10:35 -04 | 18 Apr 24 10:35 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 18 Apr 24 10:36 -04 | 18 Apr 24 10:36 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 20 Apr 24 16:01 -04 |                     |
| start     |                       | minikube | jon  | v1.32.0 | 20 Apr 24 16:07 -04 | 20 Apr 24 16:10 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 20 Apr 24 16:29 -04 | 20 Apr 24 16:30 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 02 May 24 15:29 -04 | 02 May 24 15:31 -04 |
| image     | ls                    | minikube | jon  | v1.32.0 | 02 May 24 16:11 -04 | 02 May 24 16:11 -04 |
| image     | load sonarqube.tar    | minikube | jon  | v1.32.0 | 02 May 24 16:12 -04 | 02 May 24 16:13 -04 |
| image     | ls                    | minikube | jon  | v1.32.0 | 02 May 24 16:13 -04 | 02 May 24 16:13 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 02 May 24 18:06 -04 | 02 May 24 18:07 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 02 May 24 19:58 -04 | 02 May 24 19:58 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 07 May 24 10:23 -04 | 07 May 24 10:24 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 07 May 24 10:45 -04 | 07 May 24 10:46 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 07 May 24 10:46 -04 | 07 May 24 10:47 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 07 May 24 18:47 -04 | 07 May 24 18:47 -04 |
| addons    | enable ingress        | minikube | jon  | v1.32.0 | 07 May 24 18:51 -04 | 07 May 24 18:53 -04 |
| service   | web --url             | minikube | jon  | v1.32.0 | 07 May 24 18:57 -04 |                     |
| service   | web --url -n sonar    | minikube | jon  | v1.32.0 | 07 May 24 18:57 -04 | 07 May 24 18:57 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 07 May 24 19:01 -04 | 07 May 24 19:01 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 07 May 24 19:02 -04 | 07 May 24 19:02 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 07 May 24 19:14 -04 | 07 May 24 19:14 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 07 May 24 19:15 -04 | 07 May 24 19:15 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 19 May 24 17:34 -04 |                     |
| start     |                       | minikube | jon  | v1.32.0 | 17 Oct 24 21:39 -04 |                     |
| delete    |                       | minikube | jon  | v1.32.0 | 17 Oct 24 21:42 -04 | 17 Oct 24 21:42 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 17 Oct 24 21:42 -04 | 17 Oct 24 21:44 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 17 Oct 24 23:04 -04 | 17 Oct 24 23:04 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 21 Oct 24 19:59 -04 | 21 Oct 24 20:01 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 21 Oct 24 23:26 -04 | 21 Oct 24 23:27 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 24 Oct 24 18:46 -04 | 24 Oct 24 18:48 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 25 Oct 24 00:03 -04 | 25 Oct 24 00:03 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 23 Nov 24 15:51 -04 |                     |
| start     |                       | minikube | jon  | v1.32.0 | 23 Nov 24 15:51 -04 | 23 Nov 24 15:53 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 23 Nov 24 16:01 -04 | 23 Nov 24 16:01 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 23 Nov 24 16:05 -04 | 23 Nov 24 16:05 -04 |
| addons    | enable ingress        | minikube | jon  | v1.32.0 | 23 Nov 24 16:07 -04 | 23 Nov 24 16:10 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 23 Nov 24 16:31 -04 | 23 Nov 24 16:31 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 23 Nov 24 19:12 -04 | 23 Nov 24 19:12 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 23 Nov 24 19:13 -04 | 23 Nov 24 19:13 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 07 Dec 24 10:34 -04 | 07 Dec 24 10:35 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 07 Dec 24 10:36 -04 | 07 Dec 24 10:36 -04 |
| dashboard |                       | minikube | jon  | v1.32.0 | 07 Dec 24 10:36 -04 |                     |
| addons    | enable metrics-server | minikube | jon  | v1.32.0 | 07 Dec 24 10:38 -04 | 07 Dec 24 10:38 -04 |
| dashboard |                       | minikube | jon  | v1.32.0 | 07 Dec 24 10:39 -04 |                     |
| ip        |                       | minikube | jon  | v1.32.0 | 07 Dec 24 15:35 -04 | 07 Dec 24 15:35 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 07 Dec 24 15:35 -04 | 07 Dec 24 15:35 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 07 Dec 24 16:24 -04 | 07 Dec 24 16:25 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 01 Aug 25 10:26 -04 | 01 Aug 25 10:30 -04 |
| addons    | enable metrics-server | minikube | jon  | v1.32.0 | 01 Aug 25 10:30 -04 | 01 Aug 25 10:30 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 01 Aug 25 10:36 -04 | 01 Aug 25 10:36 -04 |
| node      |                       | minikube | jon  | v1.32.0 | 01 Aug 25 11:00 -04 |                     |
| node      | list                  | minikube | jon  | v1.32.0 | 01 Aug 25 11:00 -04 |                     |
| ip        |                       | minikube | jon  | v1.32.0 | 01 Aug 25 11:00 -04 | 01 Aug 25 11:00 -04 |
| ssh       |                       | minikube | jon  | v1.32.0 | 01 Aug 25 11:00 -04 | 01 Aug 25 11:04 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 22 Aug 25 09:10 -04 | 22 Aug 25 09:13 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 22 Aug 25 09:51 -04 | 22 Aug 25 09:51 -04 |
| ip        |                       | minikube | jon  | v1.32.0 | 22 Aug 25 09:52 -04 | 22 Aug 25 09:52 -04 |
| stop      |                       | minikube | jon  | v1.32.0 | 22 Aug 25 13:26 -04 | 22 Aug 25 13:27 -04 |
| start     |                       | minikube | jon  | v1.32.0 | 10 Sep 25 11:20 -04 | 10 Sep 25 11:27 -04 |
|-----------|-----------------------|----------|------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2025/09/10 11:20:04
Running on machine: pop-os
Binary: Built with gc go1.21.3 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0910 11:20:04.806268   29589 out.go:296] Setting OutFile to fd 1 ...
I0910 11:20:04.806726   29589 out.go:348] isatty.IsTerminal(1) = true
I0910 11:20:04.806738   29589 out.go:309] Setting ErrFile to fd 2...
I0910 11:20:04.806758   29589 out.go:348] isatty.IsTerminal(2) = true
I0910 11:20:04.807486   29589 root.go:338] Updating PATH: /home/jon/.minikube/bin
I0910 11:20:04.856898   29589 out.go:303] Setting JSON to false
I0910 11:20:04.883111   29589 start.go:128] hostinfo: {"hostname":"pop-os","uptime":15110,"bootTime":1757502495,"procs":281,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"bookworm/sid","kernelVersion":"6.12.10-76061203-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"host","hostId":"5276ffb7-74a3-427c-bde8-c38866188265"}
I0910 11:20:04.883306   29589 start.go:138] virtualization: kvm host
I0910 11:20:04.952916   29589 out.go:177] üòÑ  minikube v1.32.0 on Debian bookworm/sid
I0910 11:20:05.086604   29589 notify.go:220] Checking for updates...
I0910 11:20:05.088556   29589 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0910 11:20:05.138216   29589 driver.go:378] Setting default libvirt URI to qemu:///system
I0910 11:20:05.217613   29589 docker.go:122] docker version: linux-28.4.0:Docker Engine - Community
I0910 11:20:05.217742   29589 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0910 11:20:06.860352   29589 lock.go:35] WriteFile acquiring /home/jon/.minikube/last_update_check: {Name:mkfc6280a9502b5eff5e6cfb35390074bbf8c8c9 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0910 11:20:07.012280   29589 out.go:177] üéâ  minikube 1.37.0 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.37.0
I0910 11:20:07.281008   29589 out.go:177] üí°  To disable this notice, run: 'minikube config set WantUpdateNotification false'

I0910 11:20:11.200959   29589 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (5.98318751s)
I0910 11:20:11.201559   29589 info.go:266] docker info: {ID:69940e13-1a64-4a76-be0b-1ce4d3b17ac0 Containers:3 ContainersRunning:0 ContainersPaused:0 ContainersStopped:3 Images:62 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:23 OomKillDisable:false NGoroutines:44 SystemTime:2025-09-10 11:20:11.125835483 -0400 -04 LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.12.10-76061203-generic OperatingSystem:Pop!_OS 22.04 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[::1/128 127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8188887040 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:pop-os Labels:[] ExperimentalBuild:false ServerVersion:28.4.0 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:05044ec0a9a75232cad458027ca83437aae3f4da Expected:} RuncCommit:{ID:v1.2.5-0-g59923ef Expected:} InitCommit:{ID:de40ad0 Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.27.0] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.39.2]] Warnings:<nil>}}
I0910 11:20:11.201656   29589 docker.go:295] overlay module found
I0910 11:20:11.323056   29589 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0910 11:20:11.439635   29589 start.go:298] selected driver: docker
I0910 11:20:11.439654   29589 start.go:902] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true ingress:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/jon:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0910 11:20:11.439769   29589 start.go:913] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0910 11:20:11.439914   29589 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0910 11:20:11.875886   29589 info.go:266] docker info: {ID:69940e13-1a64-4a76-be0b-1ce4d3b17ac0 Containers:3 ContainersRunning:0 ContainersPaused:0 ContainersStopped:3 Images:62 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:23 OomKillDisable:false NGoroutines:44 SystemTime:2025-09-10 11:20:11.862543088 -0400 -04 LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.12.10-76061203-generic OperatingSystem:Pop!_OS 22.04 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[::1/128 127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:8188887040 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:pop-os Labels:[] ExperimentalBuild:false ServerVersion:28.4.0 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:05044ec0a9a75232cad458027ca83437aae3f4da Expected:} RuncCommit:{ID:v1.2.5-0-g59923ef Expected:} InitCommit:{ID:de40ad0 Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.27.0] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.39.2]] Warnings:<nil>}}
I0910 11:20:11.876877   29589 cni.go:84] Creating CNI manager for ""
I0910 11:20:11.876896   29589 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0910 11:20:11.876912   29589 start_flags.go:323] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true ingress:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/jon:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0910 11:20:12.015895   29589 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0910 11:20:12.090443   29589 cache.go:121] Beginning downloading kic base image for docker with docker
I0910 11:20:12.174070   29589 out.go:177] üöú  Pulling base image ...
I0910 11:20:12.251252   29589 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 in local docker daemon
I0910 11:20:12.312313   29589 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 in local docker daemon, skipping pull
I0910 11:20:12.312325   29589 cache.go:144] gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 exists in daemon, skipping load
I0910 11:20:12.334916   29589 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0910 11:20:12.334986   29589 preload.go:148] Found local preload: /home/jon/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4
I0910 11:20:12.334993   29589 cache.go:56] Caching tarball of preloaded images
I0910 11:20:12.335133   29589 preload.go:174] Found /home/jon/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0910 11:20:12.335143   29589 cache.go:59] Finished verifying existence of preloaded tar for  v1.28.3 on docker
I0910 11:20:12.335274   29589 profile.go:148] Saving config to /home/jon/.minikube/profiles/minikube/config.json ...
I0910 11:20:12.362752   29589 cache.go:194] Successfully downloaded all kic artifacts
I0910 11:20:12.362816   29589 start.go:365] acquiring machines lock for minikube: {Name:mka900934aa978297efaed8248f1b83ac4ee4700 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0910 11:20:12.362912   29589 start.go:369] acquired machines lock for "minikube" in 79.952¬µs
I0910 11:20:12.362925   29589 start.go:96] Skipping create...Using existing machine configuration
I0910 11:20:12.362929   29589 fix.go:54] fixHost starting: 
I0910 11:20:12.363207   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:20:12.398421   29589 fix.go:102] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0910 11:20:12.398458   29589 fix.go:128] unexpected machine state, will restart: <nil>
I0910 11:20:12.591391   29589 out.go:177] üîÑ  Restarting existing docker container for "minikube" ...
I0910 11:20:12.658518   29589 cli_runner.go:164] Run: docker start minikube
I0910 11:20:16.504040   29589 cli_runner.go:217] Completed: docker start minikube: (3.845461851s)
I0910 11:20:16.504292   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:20:16.530974   29589 kic.go:430] container "minikube" state is running.
I0910 11:20:16.531425   29589 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0910 11:20:16.560903   29589 profile.go:148] Saving config to /home/jon/.minikube/profiles/minikube/config.json ...
I0910 11:20:16.561120   29589 machine.go:88] provisioning docker machine ...
I0910 11:20:16.561153   29589 ubuntu.go:169] provisioning hostname "minikube"
I0910 11:20:16.561200   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:16.589863   29589 main.go:141] libmachine: Using SSH client type: native
I0910 11:20:16.773931   29589 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0910 11:20:16.773943   29589 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0910 11:20:16.774735   29589 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:39486->127.0.0.1:32768: read: connection reset by peer
I0910 11:20:19.789479   29589 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:48218->127.0.0.1:32768: read: connection reset by peer
I0910 11:20:22.803689   29589 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:48230->127.0.0.1:32768: read: connection reset by peer
I0910 11:20:25.809629   29589 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:48236->127.0.0.1:32768: read: connection reset by peer
I0910 11:20:28.824702   29589 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:58810->127.0.0.1:32768: read: connection reset by peer
I0910 11:20:31.836196   29589 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:58822->127.0.0.1:32768: read: connection reset by peer
I0910 11:20:34.837952   29589 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:58834->127.0.0.1:32768: read: connection reset by peer
I0910 11:20:40.005397   29589 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0910 11:20:40.005474   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:40.038712   29589 main.go:141] libmachine: Using SSH client type: native
I0910 11:20:40.039146   29589 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0910 11:20:40.039161   29589 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0910 11:20:40.177427   29589 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0910 11:20:40.177462   29589 ubuntu.go:175] set auth options {CertDir:/home/jon/.minikube CaCertPath:/home/jon/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jon/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jon/.minikube/machines/server.pem ServerKeyPath:/home/jon/.minikube/machines/server-key.pem ClientKeyPath:/home/jon/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jon/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jon/.minikube}
I0910 11:20:40.177483   29589 ubuntu.go:177] setting up certificates
I0910 11:20:40.177489   29589 provision.go:83] configureAuth start
I0910 11:20:40.177553   29589 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0910 11:20:40.206879   29589 provision.go:138] copyHostCerts
I0910 11:20:40.260496   29589 exec_runner.go:144] found /home/jon/.minikube/key.pem, removing ...
I0910 11:20:40.260511   29589 exec_runner.go:203] rm: /home/jon/.minikube/key.pem
I0910 11:20:40.260587   29589 exec_runner.go:151] cp: /home/jon/.minikube/certs/key.pem --> /home/jon/.minikube/key.pem (1679 bytes)
I0910 11:20:40.284837   29589 exec_runner.go:144] found /home/jon/.minikube/ca.pem, removing ...
I0910 11:20:40.284871   29589 exec_runner.go:203] rm: /home/jon/.minikube/ca.pem
I0910 11:20:40.285027   29589 exec_runner.go:151] cp: /home/jon/.minikube/certs/ca.pem --> /home/jon/.minikube/ca.pem (1070 bytes)
I0910 11:20:40.285493   29589 exec_runner.go:144] found /home/jon/.minikube/cert.pem, removing ...
I0910 11:20:40.285514   29589 exec_runner.go:203] rm: /home/jon/.minikube/cert.pem
I0910 11:20:40.285561   29589 exec_runner.go:151] cp: /home/jon/.minikube/certs/cert.pem --> /home/jon/.minikube/cert.pem (1115 bytes)
I0910 11:20:40.285896   29589 provision.go:112] generating server cert: /home/jon/.minikube/machines/server.pem ca-key=/home/jon/.minikube/certs/ca.pem private-key=/home/jon/.minikube/certs/ca-key.pem org=jon.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0910 11:20:40.589721   29589 provision.go:172] copyRemoteCerts
I0910 11:20:40.589965   29589 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0910 11:20:40.590068   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:40.622636   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:20:40.728651   29589 ssh_runner.go:362] scp /home/jon/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1070 bytes)
I0910 11:20:41.740454   29589 ssh_runner.go:362] scp /home/jon/.minikube/machines/server.pem --> /etc/docker/server.pem (1192 bytes)
I0910 11:20:41.828187   29589 ssh_runner.go:362] scp /home/jon/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0910 11:20:41.901215   29589 provision.go:86] duration metric: configureAuth took 1.723703538s
I0910 11:20:41.901231   29589 ubuntu.go:193] setting minikube options for container-runtime
I0910 11:20:41.901424   29589 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0910 11:20:41.901474   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:41.928556   29589 main.go:141] libmachine: Using SSH client type: native
I0910 11:20:41.928918   29589 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0910 11:20:41.928925   29589 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0910 11:20:42.160016   29589 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0910 11:20:42.160097   29589 ubuntu.go:71] root file system type: overlay
I0910 11:20:42.160260   29589 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0910 11:20:42.160361   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:42.197737   29589 main.go:141] libmachine: Using SSH client type: native
I0910 11:20:42.198196   29589 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0910 11:20:42.198340   29589 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0910 11:20:42.501923   29589 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0910 11:20:42.502041   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:42.542588   29589 main.go:141] libmachine: Using SSH client type: native
I0910 11:20:42.543001   29589 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0910 11:20:42.543017   29589 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0910 11:20:42.859059   29589 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0910 11:20:42.859088   29589 machine.go:91] provisioned docker machine in 26.297962616s
I0910 11:20:42.859095   29589 start.go:300] post-start starting for "minikube" (driver="docker")
I0910 11:20:42.859104   29589 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0910 11:20:42.859182   29589 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0910 11:20:42.859235   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:42.901887   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:20:43.284080   29589 ssh_runner.go:195] Run: cat /etc/os-release
I0910 11:20:43.419697   29589 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0910 11:20:43.419731   29589 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0910 11:20:43.419738   29589 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0910 11:20:43.419743   29589 info.go:137] Remote host: Ubuntu 22.04.3 LTS
I0910 11:20:43.419754   29589 filesync.go:126] Scanning /home/jon/.minikube/addons for local assets ...
I0910 11:20:43.455436   29589 filesync.go:126] Scanning /home/jon/.minikube/files for local assets ...
I0910 11:20:43.468603   29589 start.go:303] post-start completed in 609.492562ms
I0910 11:20:43.468702   29589 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0910 11:20:43.468775   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:43.496099   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:20:43.729679   29589 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0910 11:20:43.741913   29589 fix.go:56] fixHost completed within 31.378978323s
I0910 11:20:43.741924   29589 start.go:83] releasing machines lock for "minikube", held for 31.379005491s
I0910 11:20:43.742008   29589 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0910 11:20:43.773585   29589 ssh_runner.go:195] Run: cat /version.json
I0910 11:20:43.773631   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:43.800548   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:20:43.814902   29589 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0910 11:20:43.815144   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:20:43.855271   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:20:44.027652   29589 ssh_runner.go:195] Run: systemctl --version
I0910 11:20:47.758408   29589 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (3.943461712s)
I0910 11:20:47.758463   29589 ssh_runner.go:235] Completed: systemctl --version: (3.730791614s)
I0910 11:20:47.758533   29589 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0910 11:20:48.011522   29589 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0910 11:20:48.838592   29589 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0910 11:20:48.838753   29589 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0910 11:20:48.854068   29589 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0910 11:20:48.854087   29589 start.go:472] detecting cgroup driver to use...
I0910 11:20:48.854123   29589 detect.go:199] detected "systemd" cgroup driver on host os
I0910 11:20:48.854235   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0910 11:20:49.045531   29589 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0910 11:20:49.369558   29589 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0910 11:20:49.422817   29589 containerd.go:145] configuring containerd to use "systemd" as cgroup driver...
I0910 11:20:49.422904   29589 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = true|g' /etc/containerd/config.toml"
I0910 11:20:49.583114   29589 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0910 11:20:49.641707   29589 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0910 11:20:49.737723   29589 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0910 11:20:49.766754   29589 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0910 11:20:49.851610   29589 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0910 11:20:50.376395   29589 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0910 11:20:50.617144   29589 crio.go:148] couldn't verify netfilter by "sudo sysctl net.bridge.bridge-nf-call-iptables" which might be okay. error: sudo sysctl net.bridge.bridge-nf-call-iptables: Process exited with status 255
stdout:

stderr:
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory
I0910 11:20:50.617473   29589 ssh_runner.go:195] Run: sudo modprobe br_netfilter
I0910 11:20:50.986727   29589 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0910 11:20:51.006125   29589 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0910 11:20:51.613260   29589 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0910 11:20:51.722399   29589 start.go:472] detecting cgroup driver to use...
I0910 11:20:51.722432   29589 detect.go:199] detected "systemd" cgroup driver on host os
I0910 11:20:51.722491   29589 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0910 11:20:51.749964   29589 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0910 11:20:51.750021   29589 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0910 11:20:51.902921   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0910 11:20:51.933460   29589 ssh_runner.go:195] Run: which cri-dockerd
I0910 11:20:51.938277   29589 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0910 11:20:51.953755   29589 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0910 11:20:51.985502   29589 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0910 11:20:52.197910   29589 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0910 11:20:52.317667   29589 docker.go:560] configuring docker to use "systemd" as cgroup driver...
I0910 11:20:52.317753   29589 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (129 bytes)
I0910 11:20:52.383838   29589 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0910 11:20:52.515547   29589 ssh_runner.go:195] Run: sudo systemctl restart docker
I0910 11:22:10.714414   29589 ssh_runner.go:235] Completed: sudo systemctl restart docker: (1m18.198774586s)
I0910 11:22:10.714664   29589 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0910 11:22:10.838250   29589 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0910 11:22:10.940896   29589 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0910 11:22:11.045236   29589 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0910 11:22:11.143192   29589 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0910 11:22:11.173515   29589 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0910 11:22:11.282409   29589 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0910 11:22:25.602974   29589 ssh_runner.go:235] Completed: sudo systemctl restart cri-docker: (14.320530855s)
I0910 11:22:25.603018   29589 start.go:519] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0910 11:22:25.638234   29589 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0910 11:22:25.645646   29589 start.go:540] Will wait 60s for crictl version
I0910 11:22:25.645727   29589 ssh_runner.go:195] Run: which crictl
I0910 11:22:25.652324   29589 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0910 11:22:36.037268   29589 ssh_runner.go:235] Completed: sudo /usr/bin/crictl version: (10.384905289s)
I0910 11:22:36.037293   29589 start.go:556] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.7
RuntimeApiVersion:  v1
I0910 11:22:36.037508   29589 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0910 11:22:43.374551   29589 ssh_runner.go:235] Completed: docker version --format {{.Server.Version}}: (7.337011014s)
I0910 11:22:43.374678   29589 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0910 11:22:43.539818   29589 out.go:204] üê≥  Preparing Kubernetes v1.28.3 on Docker 24.0.7 ...
I0910 11:22:43.540157   29589 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0910 11:22:43.581413   29589 ssh_runner.go:195] Run: grep 192.168.49.1	host.minikube.internal$ /etc/hosts
I0910 11:22:43.586726   29589 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.49.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0910 11:22:43.603643   29589 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0910 11:22:43.603703   29589 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0910 11:22:43.633290   29589 docker.go:671] Got preloaded images: -- stdout --
nginx:latest
httpd:latest
httpd:<none>
nginx:<none>
<none>:<none>
quay.io/argoproj/argocd:v2.12.7
<none>:<none>
<none>:<none>
<none>:<none>
<none>:<none>
<none>:<none>
jorhak/dde:1.0.7
redis:7.0.15-alpine
ghcr.io/dexidp/dex:v2.38.0
registry.k8s.io/ingress-nginx/controller:<none>
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
<none>:<none>
registry.k8s.io/metrics-server/metrics-server:<none>
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
kubernetesui/dashboard:<none>
kubernetesui/metrics-scraper:<none>
gcr.io/k8s-minikube/storage-provisioner:v5
<none>:<none>

-- /stdout --
I0910 11:22:43.633303   29589 docker.go:601] Images already preloaded, skipping extraction
I0910 11:22:43.633370   29589 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0910 11:22:43.662123   29589 docker.go:671] Got preloaded images: -- stdout --
nginx:latest
httpd:latest
httpd:<none>
nginx:<none>
<none>:<none>
quay.io/argoproj/argocd:v2.12.7
<none>:<none>
<none>:<none>
<none>:<none>
<none>:<none>
<none>:<none>
jorhak/dde:1.0.7
redis:7.0.15-alpine
ghcr.io/dexidp/dex:v2.38.0
registry.k8s.io/ingress-nginx/controller:<none>
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
<none>:<none>
registry.k8s.io/metrics-server/metrics-server:<none>
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
kubernetesui/dashboard:<none>
kubernetesui/metrics-scraper:<none>
gcr.io/k8s-minikube/storage-provisioner:v5
<none>:<none>

-- /stdout --
I0910 11:22:43.662133   29589 cache_images.go:84] Images are preloaded, skipping loading
I0910 11:22:43.662190   29589 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0910 11:22:58.791454   29589 ssh_runner.go:235] Completed: docker info --format {{.CgroupDriver}}: (15.129233769s)
I0910 11:22:58.791532   29589 cni.go:84] Creating CNI manager for ""
I0910 11:22:58.791556   29589 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0910 11:22:58.791591   29589 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0910 11:22:58.791642   29589 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.28.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0910 11:22:58.791964   29589 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.28.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0910 11:22:58.792057   29589 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.28.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0910 11:22:58.792162   29589 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.28.3
I0910 11:22:58.867490   29589 binaries.go:44] Found k8s binaries, skipping transfer
I0910 11:22:58.867589   29589 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0910 11:22:58.885696   29589 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I0910 11:22:58.924513   29589 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0910 11:22:58.960348   29589 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2090 bytes)
I0910 11:22:59.111408   29589 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0910 11:22:59.125573   29589 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0910 11:22:59.154427   29589 certs.go:56] Setting up /home/jon/.minikube/profiles/minikube for IP: 192.168.49.2
I0910 11:22:59.154445   29589 certs.go:190] acquiring lock for shared ca certs: {Name:mkaabe1a554074c68211f00ffb8f60a650b8e065 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0910 11:22:59.244452   29589 certs.go:199] skipping minikubeCA CA generation: /home/jon/.minikube/ca.key
I0910 11:22:59.252654   29589 certs.go:199] skipping proxyClientCA CA generation: /home/jon/.minikube/proxy-client-ca.key
I0910 11:22:59.270404   29589 certs.go:315] skipping minikube-user signed cert generation: /home/jon/.minikube/profiles/minikube/client.key
I0910 11:22:59.271071   29589 certs.go:315] skipping minikube signed cert generation: /home/jon/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I0910 11:22:59.290022   29589 certs.go:315] skipping aggregator signed cert generation: /home/jon/.minikube/profiles/minikube/proxy-client.key
I0910 11:22:59.290629   29589 certs.go:437] found cert: /home/jon/.minikube/certs/home/jon/.minikube/certs/ca-key.pem (1675 bytes)
I0910 11:22:59.290756   29589 certs.go:437] found cert: /home/jon/.minikube/certs/home/jon/.minikube/certs/ca.pem (1070 bytes)
I0910 11:22:59.290905   29589 certs.go:437] found cert: /home/jon/.minikube/certs/home/jon/.minikube/certs/cert.pem (1115 bytes)
I0910 11:22:59.291145   29589 certs.go:437] found cert: /home/jon/.minikube/certs/home/jon/.minikube/certs/key.pem (1679 bytes)
I0910 11:22:59.293482   29589 ssh_runner.go:362] scp /home/jon/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0910 11:22:59.393906   29589 ssh_runner.go:362] scp /home/jon/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0910 11:22:59.497724   29589 ssh_runner.go:362] scp /home/jon/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0910 11:22:59.613451   29589 ssh_runner.go:362] scp /home/jon/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0910 11:22:59.694221   29589 ssh_runner.go:362] scp /home/jon/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0910 11:22:59.828391   29589 ssh_runner.go:362] scp /home/jon/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0910 11:23:00.063511   29589 ssh_runner.go:362] scp /home/jon/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0910 11:23:00.126004   29589 ssh_runner.go:362] scp /home/jon/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0910 11:23:00.189963   29589 ssh_runner.go:362] scp /home/jon/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0910 11:23:00.331235   29589 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0910 11:23:00.416713   29589 ssh_runner.go:195] Run: openssl version
I0910 11:23:00.641982   29589 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0910 11:23:00.749048   29589 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0910 11:23:00.762955   29589 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Apr 18  2024 /usr/share/ca-certificates/minikubeCA.pem
I0910 11:23:00.763125   29589 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0910 11:23:00.815647   29589 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0910 11:23:00.839566   29589 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I0910 11:23:00.869762   29589 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0910 11:23:00.944206   29589 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0910 11:23:00.991894   29589 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0910 11:23:01.013756   29589 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0910 11:23:01.032589   29589 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0910 11:23:01.059454   29589 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0910 11:23:01.078380   29589 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true ingress:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/jon:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0910 11:23:01.078545   29589 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0910 11:23:01.159010   29589 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0910 11:23:01.183817   29589 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I0910 11:23:01.183826   29589 kubeadm.go:636] restartCluster start
I0910 11:23:01.183880   29589 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0910 11:23:01.246358   29589 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0910 11:23:01.313933   29589 kubeconfig.go:135] verify returned: extract IP: "minikube" does not appear in /home/jon/.kube/config
I0910 11:23:01.314267   29589 kubeconfig.go:146] "minikube" context is missing from /home/jon/.kube/config - will repair!
I0910 11:23:01.315116   29589 lock.go:35] WriteFile acquiring /home/jon/.kube/config: {Name:mkb8acfd011fbdd5dbd11392f844d49ce15d7c14 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0910 11:23:01.566174   29589 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0910 11:23:01.667301   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:01.667509   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:01.791577   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:01.791586   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:01.791634   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:01.805959   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:02.306152   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:02.306314   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:02.340978   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:02.807069   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:02.807325   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:02.842933   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:03.307013   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:03.307243   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:03.343233   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:03.806888   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:03.806975   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:03.823356   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:04.307054   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:04.307221   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:04.343707   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:04.806345   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:04.806549   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:04.847316   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:05.306371   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:05.306614   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:05.349470   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:05.806417   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:05.806581   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:05.838837   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:06.306757   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:06.306865   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:06.329545   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:06.806808   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:06.807001   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:06.845554   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:07.306552   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:07.306712   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:07.345536   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:07.807055   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:07.807266   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:07.845835   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:08.306763   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:08.307030   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:08.342307   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:08.806614   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:08.806729   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:08.834214   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:09.306593   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:09.306841   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:09.344214   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:09.806432   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:09.807024   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:09.962161   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:10.306319   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:10.306381   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:10.320886   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:10.806175   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:10.806347   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:10.842718   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:11.306626   29589 api_server.go:166] Checking apiserver status ...
I0910 11:23:11.306726   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0910 11:23:11.329951   29589 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0910 11:23:11.667963   29589 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I0910 11:23:11.667992   29589 kubeadm.go:1128] stopping kube-system containers ...
I0910 11:23:11.668160   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0910 11:23:11.749317   29589 docker.go:469] Stopping containers: [37924517d3ff 322daa1ce5c2 8bc508e2d65e c9f9315cc47e a066703a0088 3dcd3d0375bd aec37e602a60 d380ab1ded70 07137031436b 3c8e9b65f0c6 6892b9931f03 8cc5a643d60a f40b3946b93a 1b66d653ccac 7229096552db 601652fb7aa5 ea1cbab302d9 9dd9e7c3b5f8 c6354ec08ff1 a503a81f7cf0 cdaa7d999bd2 7f4588438406 f043f309b21e 51a1ac979d35 bc609e3c58ff 78a9dc1da528 a0dc2aa54b11 391225ae305a 5366ac312b99]
I0910 11:23:11.749403   29589 ssh_runner.go:195] Run: docker stop 37924517d3ff 322daa1ce5c2 8bc508e2d65e c9f9315cc47e a066703a0088 3dcd3d0375bd aec37e602a60 d380ab1ded70 07137031436b 3c8e9b65f0c6 6892b9931f03 8cc5a643d60a f40b3946b93a 1b66d653ccac 7229096552db 601652fb7aa5 ea1cbab302d9 9dd9e7c3b5f8 c6354ec08ff1 a503a81f7cf0 cdaa7d999bd2 7f4588438406 f043f309b21e 51a1ac979d35 bc609e3c58ff 78a9dc1da528 a0dc2aa54b11 391225ae305a 5366ac312b99
I0910 11:23:11.773394   29589 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0910 11:23:11.790232   29589 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0910 11:23:11.841170   29589 kubeadm.go:155] found existing configuration files:
-rw------- 1 root root 5643 Aug  1 14:28 /etc/kubernetes/admin.conf
-rw------- 1 root root 5656 Aug 22 13:11 /etc/kubernetes/controller-manager.conf
-rw------- 1 root root 5659 Aug  1 14:28 /etc/kubernetes/kubelet.conf
-rw------- 1 root root 5604 Aug 22 13:11 /etc/kubernetes/scheduler.conf

I0910 11:23:11.841233   29589 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0910 11:23:11.973501   29589 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0910 11:23:11.998301   29589 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0910 11:23:12.043753   29589 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 1
stdout:

stderr:
I0910 11:23:12.043842   29589 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0910 11:23:12.059130   29589 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0910 11:23:12.086216   29589 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 1
stdout:

stderr:
I0910 11:23:12.086289   29589 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0910 11:23:12.102385   29589 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0910 11:23:12.120155   29589 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0910 11:23:12.120166   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0910 11:23:26.291838   29589 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": (14.171651397s)
I0910 11:23:26.291858   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0910 11:23:27.386555   29589 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (1.094679827s)
I0910 11:23:27.386570   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0910 11:23:27.728192   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0910 11:23:27.883909   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0910 11:23:27.945408   29589 api_server.go:52] waiting for apiserver process to appear ...
I0910 11:23:27.945471   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:27.959845   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:28.473616   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:28.974213   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:29.474535   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:29.974119   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:30.473623   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:30.973853   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:31.473893   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:31.974529   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:32.474364   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:32.974017   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:33.473824   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:33.974313   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:34.474574   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:34.973907   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:35.473943   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:35.973737   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:36.473615   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:36.974244   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:37.474168   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:37.973534   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:38.473899   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:38.973700   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:39.474331   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:39.973905   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:40.474100   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:40.975054   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:41.474310   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:41.973628   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:42.473741   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:42.973888   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:43.473993   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:43.974258   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:44.474551   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:44.974238   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:45.473752   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:45.973812   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:46.473893   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:46.973841   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:47.473841   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:47.973851   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:48.473730   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:48.973752   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:49.474174   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:49.973561   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:50.474451   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:50.974289   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:51.473862   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:51.973659   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:52.473904   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:52.973831   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:53.474488   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:53.974570   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:54.474626   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:54.973899   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:55.473659   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:55.974121   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:56.474372   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:56.974061   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:57.473610   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:57.974277   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:58.477071   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:58.973656   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:59.474038   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:23:59.974409   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:00.475241   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:00.974059   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:01.474453   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:01.976917   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:02.474097   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:02.973948   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:03.473772   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:03.973873   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:04.473772   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:04.974035   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:05.473639   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:05.973783   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:06.474591   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:06.973653   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:07.474304   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:07.974297   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:08.474104   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:08.974362   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:09.474458   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:09.973757   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:10.473691   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:10.973720   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:11.474084   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:11.974084   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:12.473648   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:12.973543   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:13.473693   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:13.974148   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:14.473998   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:14.974033   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:15.474542   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:15.974735   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:16.474003   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:16.974895   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:17.474212   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:17.974416   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:18.473973   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:18.973772   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:19.473818   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:19.974861   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:20.474436   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:20.974475   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:21.474070   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:21.973618   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:22.474247   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:22.974131   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:23.473853   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:23.974588   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:24.474309   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:24.973674   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:25.474042   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:25.973613   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:26.473517   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:26.974552   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:27.474531   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:24:27.973708   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0910 11:24:28.027158   29589 logs.go:284] 2 containers: [1b66d653ccac bc609e3c58ff]
I0910 11:24:28.027292   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0910 11:24:28.064597   29589 logs.go:284] 1 containers: [f40b3946b93a]
I0910 11:24:28.064680   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0910 11:24:28.088863   29589 logs.go:284] 1 containers: [a066703a0088]
I0910 11:24:28.088933   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0910 11:24:28.110274   29589 logs.go:284] 1 containers: [7229096552db]
I0910 11:24:28.110342   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0910 11:24:28.134259   29589 logs.go:284] 1 containers: [3dcd3d0375bd]
I0910 11:24:28.134330   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0910 11:24:28.158112   29589 logs.go:284] 1 containers: [aec37e602a60]
I0910 11:24:28.158177   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0910 11:24:28.179590   29589 logs.go:284] 0 containers: []
W0910 11:24:28.179601   29589 logs.go:286] No container was found matching "kindnet"
I0910 11:24:28.179660   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_controller_ingress --format={{.ID}}
I0910 11:24:28.202446   29589 logs.go:284] 2 containers: [4e7ea83439ba a4ed9d1e8621]
I0910 11:24:28.202508   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0910 11:24:28.225210   29589 logs.go:284] 1 containers: [322daa1ce5c2]
I0910 11:24:28.225322   29589 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0910 11:24:28.246936   29589 logs.go:284] 1 containers: [f481f8223e61]
I0910 11:24:28.247000   29589 logs.go:123] Gathering logs for dmesg ...
I0910 11:24:28.247030   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0910 11:24:28.416927   29589 logs.go:123] Gathering logs for describe nodes ...
I0910 11:24:28.416943   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0910 11:24:50.433753   29589 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": (22.016786231s)
W0910 11:24:50.433776   29589 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0910 15:24:50.422328    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.422918    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.424403    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.424834    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.428333    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0910 15:24:50.422328    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.422918    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.424403    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.424834    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
E0910 15:24:50.428333    2193 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp [::1]:8443: connect: connection refused
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0910 11:24:50.433783   29589 logs.go:123] Gathering logs for kube-proxy [3dcd3d0375bd] ...
I0910 11:24:50.433813   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dcd3d0375bd"
I0910 11:24:50.501391   29589 logs.go:123] Gathering logs for kube-controller-manager [aec37e602a60] ...
I0910 11:24:50.501403   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 aec37e602a60"
I0910 11:24:51.469634   29589 logs.go:123] Gathering logs for Docker ...
I0910 11:24:51.469651   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0910 11:24:51.682645   29589 logs.go:123] Gathering logs for kubelet ...
I0910 11:24:51.682676   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0910 11:24:51.761306   29589 logs.go:123] Gathering logs for kube-apiserver [1b66d653ccac] ...
I0910 11:24:51.761323   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 1b66d653ccac"
I0910 11:24:52.852611   29589 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 1b66d653ccac": (1.091273775s)
I0910 11:24:52.874743   29589 logs.go:123] Gathering logs for kube-apiserver [bc609e3c58ff] ...
I0910 11:24:52.874755   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bc609e3c58ff"
W0910 11:24:52.897129   29589 logs.go:130] failed kube-apiserver [bc609e3c58ff]: command: /bin/bash -c "docker logs --tail 400 bc609e3c58ff" /bin/bash -c "docker logs --tail 400 bc609e3c58ff": Process exited with status 1
stdout:

stderr:
Error response from daemon: No such container: bc609e3c58ff
 output: 
** stderr ** 
Error response from daemon: No such container: bc609e3c58ff

** /stderr **
I0910 11:24:52.897137   29589 logs.go:123] Gathering logs for coredns [a066703a0088] ...
I0910 11:24:52.897145   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a066703a0088"
I0910 11:24:53.897125   29589 logs.go:123] Gathering logs for kube-scheduler [7229096552db] ...
I0910 11:24:53.897142   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 7229096552db"
I0910 11:24:55.051585   29589 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 7229096552db": (1.154427354s)
I0910 11:24:55.070091   29589 logs.go:123] Gathering logs for controller_ingress [4e7ea83439ba] ...
I0910 11:24:55.070106   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4e7ea83439ba"
I0910 11:24:55.284461   29589 logs.go:123] Gathering logs for etcd [f40b3946b93a] ...
I0910 11:24:55.284474   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f40b3946b93a"
I0910 11:24:56.110123   29589 logs.go:123] Gathering logs for controller_ingress [a4ed9d1e8621] ...
I0910 11:24:56.110143   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a4ed9d1e8621"
W0910 11:24:56.136025   29589 logs.go:130] failed controller_ingress [a4ed9d1e8621]: command: /bin/bash -c "docker logs --tail 400 a4ed9d1e8621" /bin/bash -c "docker logs --tail 400 a4ed9d1e8621": Process exited with status 1
stdout:

stderr:
Error response from daemon: No such container: a4ed9d1e8621
 output: 
** stderr ** 
Error response from daemon: No such container: a4ed9d1e8621

** /stderr **
I0910 11:24:56.136036   29589 logs.go:123] Gathering logs for storage-provisioner [322daa1ce5c2] ...
I0910 11:24:56.136044   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 322daa1ce5c2"
I0910 11:24:56.896517   29589 logs.go:123] Gathering logs for kubernetes-dashboard [f481f8223e61] ...
I0910 11:24:56.896534   29589 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f481f8223e61"
I0910 11:24:57.170362   29589 logs.go:123] Gathering logs for container status ...
I0910 11:24:57.170375   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0910 11:24:59.832107   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:25:00.031381   29589 api_server.go:72] duration metric: took 1m32.085963808s to wait for apiserver process to appear ...
I0910 11:25:00.031404   29589 api_server.go:88] waiting for apiserver healthz status ...
I0910 11:25:00.031427   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:00.032658   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:00.032761   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:00.033723   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:00.535180   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:00.536200   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:01.034415   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:01.036773   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:01.534741   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:01.536693   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:02.034546   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:02.035168   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:02.533997   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:02.535307   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:03.034782   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:03.035306   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:03.534593   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:03.535717   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:04.033999   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:04.034920   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:04.534335   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:04.535300   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:05.034186   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:05.081201   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:05.534220   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:05.534597   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:06.034368   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:06.034848   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:06.535233   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:06.536180   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:07.034200   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:07.035164   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:07.534424   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:07.535730   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:08.033883   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:08.034307   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:08.534470   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:08.534841   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:09.033862   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:09.034293   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:09.534072   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:09.534946   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:10.034509   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:10.132069   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:10.534834   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:10.535329   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:11.033840   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:11.034203   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:11.534891   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:11.535760   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:12.034598   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:12.036103   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:12.534287   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:12.534600   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:13.034662   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:13.035509   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0910 11:25:13.534727   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:18.536153   29589 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0910 11:25:18.536212   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:19.494540   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0910 11:25:19.494562   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0910 11:25:19.494574   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:19.509745   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0910 11:25:19.509760   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0910 11:25:19.534336   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:19.714661   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0910 11:25:19.714677   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0910 11:25:20.034320   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:20.224119   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[-]etcd failed: reason withheld
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[-]poststarthook/start-service-ip-repair-controllers failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:20.224143   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[-]etcd failed: reason withheld
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[-]poststarthook/start-service-ip-repair-controllers failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[-]poststarthook/bootstrap-controller failed: reason withheld
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:20.534587   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:20.539300   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[-]poststarthook/start-service-ip-repair-controllers failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:20.539325   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[-]poststarthook/start-service-ip-repair-controllers failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:21.033855   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:21.047618   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:21.047656   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:21.534555   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:21.543324   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:21.543347   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:22.033846   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:22.041085   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:22.041228   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:22.533896   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:22.545830   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:22.545854   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:23.033884   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:23.039639   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:23.039663   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:23.533818   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:23.541410   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:23.541465   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:24.033834   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:24.039032   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:24.039052   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:24.534608   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:25.058723   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:25.294045   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:25.294129   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:25.309237   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:25.309255   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:25.534894   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:25.981710   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:25.981742   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:26.034768   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:26.049529   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:26.049559   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:26.533829   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:26.538295   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:26.538311   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:27.034414   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:27.053356   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:27.053379   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:27.534563   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:27.539453   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:27.539478   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:28.033900   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:28.037971   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:28.037984   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:28.533978   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:28.563641   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:28.563699   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:29.034286   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:29.038582   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:29.038599   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:29.534308   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:29.541124   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:29.541148   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:30.034472   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:30.193811   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:30.193836   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:30.534841   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:30.540699   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:30.540729   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:31.034343   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:31.038700   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:31.038728   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:31.534149   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:31.539811   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:31.539832   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:32.034837   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:32.041916   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:32.041939   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:32.534006   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:32.551732   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:32.551773   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:33.033858   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:33.037872   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:33.037882   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:33.533947   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:33.538255   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:33.538269   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:34.033901   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:34.038996   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:34.039016   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:34.534117   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:34.538340   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:34.538357   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:35.033969   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:35.303994   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:35.304028   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:35.533913   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:35.548604   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:35.548636   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:36.034165   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:36.041722   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:36.041749   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:36.533891   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:36.540854   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:36.540920   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:37.034547   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:37.046126   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:37.046185   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:37.534566   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:37.738482   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:37.738507   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:38.034766   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:38.052579   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:38.052609   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:38.534898   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:38.539865   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:38.539880   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:39.035471   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:39.055618   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:39.055650   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:39.534632   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:39.542377   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:39.542393   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:40.034127   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:40.092364   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:40.092381   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:40.534347   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:40.542355   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:40.542377   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:41.033857   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:41.038865   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:41.038879   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:41.534528   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:41.549354   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:41.549422   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:42.034738   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:42.076911   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:42.076929   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:42.534630   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:42.549699   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:42.549870   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:43.033847   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:43.043892   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:43.043908   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:43.534324   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:43.539367   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:43.539383   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:44.034755   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:44.041004   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:44.041022   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:44.534165   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:44.563308   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:44.563328   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:45.034120   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:45.195946   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:45.196002   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:45.533878   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:46.084531   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:46.084554   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:46.084570   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:46.094222   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:46.094243   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:46.535024   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:46.549660   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:46.549716   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:47.034543   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:47.050514   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:47.050563   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:47.534528   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:47.538559   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:47.538571   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:48.034606   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:48.038689   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:48.038703   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:48.533929   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:48.548526   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:48.548583   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:49.033935   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:49.216180   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:49.216230   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:49.534474   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:49.541417   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:49.541440   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:50.033839   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:50.109541   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:50.109558   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:50.534626   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:50.541780   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:50.541830   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:51.034689   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:51.049533   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:51.049565   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:51.534439   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:51.549255   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:51.549303   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:52.033837   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:52.037996   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:52.038034   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:52.534273   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:52.548776   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:52.548894   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:53.034238   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:53.038266   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:53.038284   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:53.534068   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:53.544923   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:53.544951   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:54.033829   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:54.038521   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:54.038538   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:54.534758   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:54.553716   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:54.553736   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:55.034169   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:55.080501   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:55.080515   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:55.534238   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:55.545663   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:55.545704   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:56.034430   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:56.038747   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:56.038758   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:56.534068   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:56.538677   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:56.538690   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:57.034833   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:57.039041   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:57.039053   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:57.533836   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:57.538002   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0910 11:25:57.538014   29589 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0910 11:25:58.034217   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:25:58.049365   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 200:
ok
I0910 11:25:58.094637   29589 api_server.go:141] control plane version: v1.28.3
I0910 11:25:58.094656   29589 api_server.go:131] duration metric: took 58.063244885s to wait for apiserver health ...
I0910 11:25:58.094671   29589 cni.go:84] Creating CNI manager for ""
I0910 11:25:58.094696   29589 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0910 11:25:58.572784   29589 out.go:177] üîó  Configuring bridge CNI (Container Networking Interface) ...
I0910 11:25:59.105997   29589 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0910 11:25:59.120760   29589 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0910 11:25:59.144962   29589 system_pods.go:43] waiting for kube-system pods to appear ...
I0910 11:26:00.201979   29589 system_pods.go:59] 8 kube-system pods found
I0910 11:26:00.202009   29589 system_pods.go:61] "coredns-5dd5756b68-kqfct" [9a5457c1-87d7-44b1-a6cf-b1224884085c] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0910 11:26:00.202016   29589 system_pods.go:61] "etcd-minikube" [084a63b3-d616-4d15-bbb1-e91f8271129b] Running
I0910 11:26:00.202026   29589 system_pods.go:61] "kube-apiserver-minikube" [c380e2b7-6f4b-439a-b891-b0d355b9ddac] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0910 11:26:00.202034   29589 system_pods.go:61] "kube-controller-manager-minikube" [6d905a86-ce21-404a-87a6-21938cd419ff] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0910 11:26:00.202041   29589 system_pods.go:61] "kube-proxy-85xrx" [4a030662-f3c7-414e-8a94-c791c50b9c51] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0910 11:26:00.202047   29589 system_pods.go:61] "kube-scheduler-minikube" [3bbf171a-949e-4b1e-b935-0aec7f389399] Running
I0910 11:26:00.202054   29589 system_pods.go:61] "metrics-server-7c66d45ddc-xvkxw" [781be241-9fe8-4b42-8e6b-9ce08c9be9e8] Running / Ready:ContainersNotReady (containers with unready status: [metrics-server]) / ContainersReady:ContainersNotReady (containers with unready status: [metrics-server])
I0910 11:26:00.202062   29589 system_pods.go:61] "storage-provisioner" [c3cbfba1-9d43-4108-b1e5-8be7cce828a5] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0910 11:26:00.202069   29589 system_pods.go:74] duration metric: took 1.057096948s to wait for pod list to return data ...
I0910 11:26:00.202077   29589 node_conditions.go:102] verifying NodePressure condition ...
I0910 11:26:01.601160   29589 node_conditions.go:122] node storage ephemeral capacity is 514937084Ki
I0910 11:26:01.601464   29589 node_conditions.go:123] node cpu capacity is 4
I0910 11:26:01.601500   29589 node_conditions.go:105] duration metric: took 1.399417157s to run NodePressure ...
I0910 11:26:01.601524   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I0910 11:26:33.560880   29589 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml": (31.959332877s)
I0910 11:26:33.560898   29589 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0910 11:26:33.573004   29589 ops.go:34] apiserver oom_adj: -16
I0910 11:26:33.573015   29589 kubeadm.go:640] restartCluster took 3m32.389183588s
I0910 11:26:33.573020   29589 kubeadm.go:406] StartCluster complete in 3m32.494648264s
I0910 11:26:33.573034   29589 settings.go:142] acquiring lock: {Name:mk9eba9efcc5a7d08004918e8c955b27af3032ae Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0910 11:26:33.685156   29589 settings.go:150] Updating kubeconfig:  /home/jon/.kube/config
I0910 11:26:33.685653   29589 lock.go:35] WriteFile acquiring /home/jon/.kube/config: {Name:mkb8acfd011fbdd5dbd11392f844d49ce15d7c14 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0910 11:26:33.686573   29589 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0910 11:26:33.686908   29589 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0910 11:26:33.686941   29589 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:true ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volumesnapshots:false]
I0910 11:26:33.686978   29589 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0910 11:26:33.686989   29589 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W0910 11:26:33.686993   29589 addons.go:240] addon storage-provisioner should already be in state true
I0910 11:26:33.687036   29589 host.go:66] Checking if "minikube" exists ...
I0910 11:26:33.687173   29589 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0910 11:26:33.687183   29589 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0910 11:26:33.687400   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:26:33.687460   29589 addons.go:69] Setting dashboard=true in profile "minikube"
I0910 11:26:33.687475   29589 addons.go:231] Setting addon dashboard=true in "minikube"
W0910 11:26:33.687485   29589 addons.go:240] addon dashboard should already be in state true
I0910 11:26:33.687519   29589 host.go:66] Checking if "minikube" exists ...
I0910 11:26:33.687673   29589 addons.go:69] Setting ingress=true in profile "minikube"
I0910 11:26:33.687688   29589 addons.go:231] Setting addon ingress=true in "minikube"
W0910 11:26:33.687692   29589 addons.go:240] addon ingress should already be in state true
I0910 11:26:33.687738   29589 host.go:66] Checking if "minikube" exists ...
I0910 11:26:33.687911   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:26:33.688316   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:26:33.688363   29589 addons.go:69] Setting metrics-server=true in profile "minikube"
I0910 11:26:33.688374   29589 addons.go:231] Setting addon metrics-server=true in "minikube"
W0910 11:26:33.688378   29589 addons.go:240] addon metrics-server should already be in state true
I0910 11:26:33.688405   29589 host.go:66] Checking if "minikube" exists ...
I0910 11:26:33.688579   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:26:33.690832   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:26:34.450281   29589 out.go:177]     ‚ñ™ Using image docker.io/kubernetesui/metrics-scraper:v1.0.8
I0910 11:26:33.745989   29589 addons.go:231] Setting addon default-storageclass=true in "minikube"
W0910 11:26:35.224634   29589 addons.go:240] addon default-storageclass should already be in state true
I0910 11:26:35.224670   29589 host.go:66] Checking if "minikube" exists ...
I0910 11:26:34.450141   29589 out.go:177]     ‚ñ™ Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0
I0910 11:26:35.224594   29589 out.go:177]     ‚ñ™ Using image registry.k8s.io/metrics-server/metrics-server:v0.6.4
I0910 11:26:35.225397   29589 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0910 11:26:35.545864   29589 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0910 11:26:35.792407   29589 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0910 11:26:36.610099   29589 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0910 11:26:36.637260   29589 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I0910 11:26:37.018616   29589 out.go:177]     ‚ñ™ Using image registry.k8s.io/ingress-nginx/controller:v1.9.4
I0910 11:26:37.191542   29589 out.go:177]     ‚ñ™ Using image docker.io/kubernetesui/dashboard:v2.7.0
I0910 11:26:37.199763   29589 addons.go:423] installing /etc/kubernetes/addons/metrics-apiservice.yaml
I0910 11:26:37.214982   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-apiservice.yaml (424 bytes)
I0910 11:26:37.214982   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0910 11:26:37.215069   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:26:37.215070   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:26:37.215098   29589 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0910 11:26:37.215105   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0910 11:26:37.215156   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:26:37.691112   29589 out.go:177] üîé  Verifying Kubernetes components...
I0910 11:26:37.244508   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:26:37.244624   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:26:37.249303   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:26:37.637825   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-ns.yaml
I0910 11:26:38.562098   29589 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0910 11:26:37.863579   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-ns.yaml (759 bytes)
I0910 11:26:37.863579   29589 out.go:177]     ‚ñ™ Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0
I0910 11:26:38.027471   29589 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0910 11:26:38.027502   29589 addons.go:423] installing /etc/kubernetes/addons/metrics-server-deployment.yaml
I0910 11:26:38.029693   29589 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0910 11:26:38.562633   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:26:39.028068   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-server-deployment.yaml (1907 bytes)
I0910 11:26:39.040175   29589 addons.go:423] installing /etc/kubernetes/addons/ingress-deploy.yaml
I0910 11:26:39.040195   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/ingress-deploy.yaml (16103 bytes)
I0910 11:26:39.040293   29589 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0910 11:26:39.077253   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:26:39.103510   29589 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml": (5.41692058s)
I0910 11:26:39.103599   29589 start.go:899] CoreDNS already contains "host.minikube.internal" host record, skipping...
I0910 11:26:39.103629   29589 api_server.go:52] waiting for apiserver process to appear ...
I0910 11:26:39.103686   29589 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0910 11:26:39.432771   29589 addons.go:423] installing /etc/kubernetes/addons/metrics-server-rbac.yaml
I0910 11:26:39.432782   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-server-rbac.yaml (2175 bytes)
I0910 11:26:39.458711   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-clusterrole.yaml
I0910 11:26:39.458722   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrole.yaml (1001 bytes)
I0910 11:26:39.523508   29589 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/jon/.minikube/machines/minikube/id_rsa Username:docker}
I0910 11:26:39.703357   29589 addons.go:423] installing /etc/kubernetes/addons/metrics-server-service.yaml
I0910 11:26:39.703368   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-server-service.yaml (446 bytes)
I0910 11:26:39.704719   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml
I0910 11:26:39.704730   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml (1018 bytes)
I0910 11:26:39.759347   29589 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/ingress-deploy.yaml
I0910 11:26:39.832446   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-configmap.yaml
I0910 11:26:39.996318   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-configmap.yaml (837 bytes)
I0910 11:26:39.832567   29589 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0910 11:26:40.620269   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-dp.yaml
I0910 11:26:40.620278   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-dp.yaml (4288 bytes)
I0910 11:26:41.580669   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-role.yaml
I0910 11:26:41.580708   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-role.yaml (1724 bytes)
I0910 11:26:41.650944   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-rolebinding.yaml
I0910 11:26:41.650982   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-rolebinding.yaml (1046 bytes)
I0910 11:26:41.774724   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-sa.yaml
I0910 11:26:41.774735   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-sa.yaml (837 bytes)
I0910 11:26:41.926256   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-secret.yaml
I0910 11:26:41.926275   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-secret.yaml (1389 bytes)
I0910 11:26:42.064975   29589 addons.go:423] installing /etc/kubernetes/addons/dashboard-svc.yaml
I0910 11:26:42.064985   29589 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-svc.yaml (1294 bytes)
I0910 11:26:42.293775   29589 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0910 11:26:48.462681   29589 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (9.434902088s)
I0910 11:26:58.789928   29589 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (19.761652373s)
I0910 11:26:58.790089   29589 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (19.686368396s)
I0910 11:26:58.790121   29589 api_server.go:72] duration metric: took 21.573545504s to wait for apiserver process to appear ...
I0910 11:26:58.790133   29589 api_server.go:88] waiting for apiserver healthz status ...
I0910 11:26:58.790164   29589 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0910 11:26:58.805394   29589 api_server.go:279] https://192.168.49.2:8443/healthz returned 200:
ok
I0910 11:26:58.808068   29589 api_server.go:141] control plane version: v1.28.3
I0910 11:26:58.808091   29589 api_server.go:131] duration metric: took 17.945314ms to wait for apiserver health ...
I0910 11:26:58.808106   29589 system_pods.go:43] waiting for kube-system pods to appear ...
I0910 11:27:00.278670   29589 system_pods.go:59] 8 kube-system pods found
I0910 11:27:00.278686   29589 system_pods.go:61] "coredns-5dd5756b68-kqfct" [9a5457c1-87d7-44b1-a6cf-b1224884085c] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0910 11:27:00.278692   29589 system_pods.go:61] "etcd-minikube" [084a63b3-d616-4d15-bbb1-e91f8271129b] Running
I0910 11:27:00.278696   29589 system_pods.go:61] "kube-apiserver-minikube" [c380e2b7-6f4b-439a-b891-b0d355b9ddac] Running
I0910 11:27:00.278703   29589 system_pods.go:61] "kube-controller-manager-minikube" [6d905a86-ce21-404a-87a6-21938cd419ff] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0910 11:27:00.278708   29589 system_pods.go:61] "kube-proxy-85xrx" [4a030662-f3c7-414e-8a94-c791c50b9c51] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0910 11:27:00.278712   29589 system_pods.go:61] "kube-scheduler-minikube" [3bbf171a-949e-4b1e-b935-0aec7f389399] Running
I0910 11:27:00.278718   29589 system_pods.go:61] "metrics-server-7c66d45ddc-xvkxw" [781be241-9fe8-4b42-8e6b-9ce08c9be9e8] Running / Ready:ContainersNotReady (containers with unready status: [metrics-server]) / ContainersReady:ContainersNotReady (containers with unready status: [metrics-server])
I0910 11:27:00.278723   29589 system_pods.go:61] "storage-provisioner" [c3cbfba1-9d43-4108-b1e5-8be7cce828a5] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0910 11:27:00.278728   29589 system_pods.go:74] duration metric: took 1.470616377s to wait for pod list to return data ...
I0910 11:27:00.278734   29589 kubeadm.go:581] duration metric: took 23.062166021s to wait for : map[apiserver:true system_pods:true] ...
I0910 11:27:00.278745   29589 node_conditions.go:102] verifying NodePressure condition ...
I0910 11:27:01.755357   29589 node_conditions.go:122] node storage ephemeral capacity is 514937084Ki
I0910 11:27:01.755375   29589 node_conditions.go:123] node cpu capacity is 4
I0910 11:27:01.755387   29589 node_conditions.go:105] duration metric: took 1.476636412s to run NodePressure ...
I0910 11:27:01.755402   29589 start.go:228] waiting for startup goroutines ...
I0910 11:27:14.594161   29589 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/ingress-deploy.yaml: (34.834792943s)
I0910 11:27:14.594192   29589 addons.go:467] Verifying addon ingress=true in "minikube"
I0910 11:27:15.220080   29589 out.go:177] üîé  Verifying ingress addon...
I0910 11:27:14.594267   29589 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: (34.597613671s)
I0910 11:27:14.594325   29589 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: (32.300535129s)
I0910 11:27:15.529782   29589 addons.go:467] Verifying addon metrics-server=true in "minikube"
I0910 11:27:15.988256   29589 out.go:177] üí°  Some dashboard features require the metrics-server addon. To enable all features please run:

	minikube addons enable metrics-server	


I0910 11:27:15.530488   29589 kapi.go:75] Waiting for pod with label "app.kubernetes.io/name=ingress-nginx" in ns "ingress-nginx" ...
I0910 11:27:17.415995   29589 kapi.go:86] Found 3 Pods for label selector app.kubernetes.io/name=ingress-nginx
I0910 11:27:17.416011   29589 kapi.go:107] duration metric: took 1.88552355s to wait for app.kubernetes.io/name=ingress-nginx ...
I0910 11:27:17.696994   29589 out.go:177] üåü  Enabled addons: default-storageclass, storage-provisioner, metrics-server, dashboard, ingress
I0910 11:27:17.939711   29589 addons.go:502] enable addons completed in 44.252741452s: enabled=[default-storageclass storage-provisioner metrics-server dashboard ingress]
I0910 11:27:17.939916   29589 start.go:233] waiting for cluster config update ...
I0910 11:27:17.939960   29589 start.go:242] writing updated cluster config ...
I0910 11:27:17.940337   29589 ssh_runner.go:195] Run: rm -f paused
I0910 11:27:19.067928   29589 ssh_runner.go:235] Completed: rm -f paused: (1.127571833s)
I0910 11:27:49.668880   29589 start.go:600] kubectl: 1.28.3, cluster: 1.28.3 (minor skew: 0)
I0910 11:27:49.968242   29589 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* Sep 10 15:35:27 minikube cri-dockerd[799]: time="2025-09-10T15:35:27Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/3f5c03bdc10a18c0b9e9db0bc79556395f829cc269472160021312ae26647e0a/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:35:28 minikube cri-dockerd[799]: time="2025-09-10T15:35:28Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/032b528f29fb1ae87bd52bc88c22b8d922f9e4878a03322186c809f5ce46b6c7/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:35:30 minikube dockerd[456]: time="2025-09-10T15:35:30.107595256Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:35:30 minikube dockerd[456]: time="2025-09-10T15:35:30.107693327Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:35:32 minikube dockerd[456]: time="2025-09-10T15:35:32.971691367Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:35:32 minikube dockerd[456]: time="2025-09-10T15:35:32.971982821Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:35:56 minikube dockerd[456]: time="2025-09-10T15:35:56.664879302Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:35:56 minikube dockerd[456]: time="2025-09-10T15:35:56.664904126Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:36:03 minikube dockerd[456]: time="2025-09-10T15:36:03.078755149Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:36:03 minikube dockerd[456]: time="2025-09-10T15:36:03.078806412Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:36:49 minikube dockerd[456]: time="2025-09-10T15:36:49.365269699Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:36:49 minikube dockerd[456]: time="2025-09-10T15:36:49.365484582Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:36:53 minikube dockerd[456]: time="2025-09-10T15:36:53.827666704Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:36:53 minikube dockerd[456]: time="2025-09-10T15:36:53.827747134Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:38:17 minikube dockerd[456]: time="2025-09-10T15:38:17.191059680Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:38:17 minikube dockerd[456]: time="2025-09-10T15:38:17.191100457Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:38:23 minikube dockerd[456]: time="2025-09-10T15:38:23.777446952Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:38:23 minikube dockerd[456]: time="2025-09-10T15:38:23.777525258Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:41:00 minikube cri-dockerd[799]: time="2025-09-10T15:41:00Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/adaa13a584febf5fc189f6261e1b9a555d7fa5cd268c02580e8ff60d73aff36b/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:41:03 minikube dockerd[456]: time="2025-09-10T15:41:03.149159643Z" level=info msg="ignoring event" container=adaa13a584febf5fc189f6261e1b9a555d7fa5cd268c02580e8ff60d73aff36b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 10 15:41:04 minikube dockerd[456]: time="2025-09-10T15:41:04.236301289Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:41:04 minikube dockerd[456]: time="2025-09-10T15:41:04.236327857Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:41:12 minikube cri-dockerd[799]: time="2025-09-10T15:41:12Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/e1f2ec387d3d2bb340ac4ecaa095d3eabf756633ca2254b0ae92fb3971dac83c/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:41:16 minikube dockerd[456]: time="2025-09-10T15:41:16.874419836Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:41:16 minikube dockerd[456]: time="2025-09-10T15:41:16.874506256Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:44:00 minikube dockerd[456]: time="2025-09-10T15:44:00.785769557Z" level=info msg="ignoring event" container=e1f2ec387d3d2bb340ac4ecaa095d3eabf756633ca2254b0ae92fb3971dac83c module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 10 15:44:01 minikube dockerd[456]: time="2025-09-10T15:44:01.340511473Z" level=info msg="ignoring event" container=3f5c03bdc10a18c0b9e9db0bc79556395f829cc269472160021312ae26647e0a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 10 15:44:02 minikube dockerd[456]: time="2025-09-10T15:44:02.042176681Z" level=info msg="ignoring event" container=032b528f29fb1ae87bd52bc88c22b8d922f9e4878a03322186c809f5ce46b6c7 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 10 15:44:20 minikube cri-dockerd[799]: time="2025-09-10T15:44:20Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/cddd4e1c1bfb161147e3c2d070f0f3707a2c816695c6b41829dd928630898d91/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:44:20 minikube cri-dockerd[799]: time="2025-09-10T15:44:20Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/55256f51597e61d399b551df38431e783b92c254c3af7855c2c7e111f766cce3/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:45:10 minikube cri-dockerd[799]: time="2025-09-10T15:45:10Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/9bab79328dc7790feb6d1362cb69da3a1b866623828e5763789addbe642e049a/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:45:13 minikube dockerd[456]: time="2025-09-10T15:45:13.479460870Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:45:13 minikube dockerd[456]: time="2025-09-10T15:45:13.479570922Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:45:30 minikube dockerd[456]: time="2025-09-10T15:45:30.925089859Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:45:30 minikube dockerd[456]: time="2025-09-10T15:45:30.925185670Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:45:38 minikube dockerd[456]: time="2025-09-10T15:45:38.063926386Z" level=info msg="ignoring event" container=9bab79328dc7790feb6d1362cb69da3a1b866623828e5763789addbe642e049a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 10 15:45:38 minikube dockerd[456]: time="2025-09-10T15:45:38.095952670Z" level=info msg="ignoring event" container=cddd4e1c1bfb161147e3c2d070f0f3707a2c816695c6b41829dd928630898d91 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 10 15:45:38 minikube dockerd[456]: time="2025-09-10T15:45:38.199508937Z" level=info msg="ignoring event" container=55256f51597e61d399b551df38431e783b92c254c3af7855c2c7e111f766cce3 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Sep 10 15:45:47 minikube cri-dockerd[799]: time="2025-09-10T15:45:47Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/2bbb450c4515411e948321a94dd586db4e8b310b2d5b4ffb9caf081b36b97f19/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:45:47 minikube cri-dockerd[799]: time="2025-09-10T15:45:47Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/da38aae0a346ac862e57324a539f6dde7758229ed742099f92602d25b6e61b95/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Sep 10 15:45:49 minikube dockerd[456]: time="2025-09-10T15:45:49.730566910Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:45:49 minikube dockerd[456]: time="2025-09-10T15:45:49.730728458Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:45:51 minikube dockerd[456]: time="2025-09-10T15:45:51.856214693Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:45:51 minikube dockerd[456]: time="2025-09-10T15:45:51.856299056Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:46:05 minikube dockerd[456]: time="2025-09-10T15:46:05.090653884Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:46:05 minikube dockerd[456]: time="2025-09-10T15:46:05.090694796Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:46:07 minikube dockerd[456]: time="2025-09-10T15:46:07.942410591Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:46:07 minikube dockerd[456]: time="2025-09-10T15:46:07.942488755Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:46:33 minikube dockerd[456]: time="2025-09-10T15:46:33.541015862Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:46:33 minikube dockerd[456]: time="2025-09-10T15:46:33.541092836Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:46:37 minikube dockerd[456]: time="2025-09-10T15:46:37.846308146Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:46:37 minikube dockerd[456]: time="2025-09-10T15:46:37.846337567Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:47:30 minikube dockerd[456]: time="2025-09-10T15:47:30.287866054Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:47:30 minikube dockerd[456]: time="2025-09-10T15:47:30.288297903Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:47:32 minikube dockerd[456]: time="2025-09-10T15:47:32.734171663Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:47:32 minikube dockerd[456]: time="2025-09-10T15:47:32.734200179Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:48:55 minikube dockerd[456]: time="2025-09-10T15:48:55.067543629Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:48:55 minikube dockerd[456]: time="2025-09-10T15:48:55.067644156Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Sep 10 15:49:03 minikube dockerd[456]: time="2025-09-10T15:49:03.472496786Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Sep 10 15:49:03 minikube dockerd[456]: time="2025-09-10T15:49:03.472579213Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                             CREATED             STATE               NAME                               ATTEMPT             POD ID              POD
f65a152300df0       redis@sha256:c9d92d840fd011c908f040592857c724ae6d877f2aba5c40ad963276507386b2                     17 minutes ago      Running             redis                              3                   9c43a2e0ea483       argocd-redis-77c9575655-lkhcs
acbbc4c200fb9       ghcr.io/dexidp/dex@sha256:b1d793440a98d7ecde7fa5dbc8cee1204ef0e8918d9e51ef6201f50d12d55925        17 minutes ago      Running             dex                                3                   1b009003b14b9       argocd-dex-server-799769c4-hgx5t
e308ee89d946d       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   18 minutes ago      Running             argocd-repo-server                 3                   c38399d250d3b       argocd-repo-server-855847b666-wsr8c
ba6396ef0d704       07655ddf2eebe                                                                                     19 minutes ago      Running             kubernetes-dashboard               7                   fb16694676013       kubernetes-dashboard-8694d4445c-bd674
ae46672f71f8b       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   20 minutes ago      Running             argocd-server                      3                   292154aca68e8       argocd-server-85c8dc874f-hwzp6
dfa0b5bb22f0a       6e38f40d628db                                                                                     20 minutes ago      Running             storage-provisioner                18                  d4fe936905831       storage-provisioner
993900edcec08       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   20 minutes ago      Running             argocd-notifications-controller    3                   e78bb6f9bd8c5       argocd-notifications-controller-5fddcdc68b-pzkwc
43deb44ab0a56       httpd@sha256:027c678f36d3cd3dd2b44ad1e963e81be66f9eba065381c1126d3019fffeb01a                     20 minutes ago      Running             apache                             1                   7037bc485f208       apache
8e506595cd9d7       a608c686bac93                                                                                     20 minutes ago      Running             metrics-server                     8                   fae51eb7fc656       metrics-server-7c66d45ddc-xvkxw
046975e21aab9       5aa0bf4798fa2                                                                                     20 minutes ago      Running             controller                         7                   0d562dc907919       ingress-nginx-controller-7c6974c4d8-2bjx2
d7dee50f7ea91       07655ddf2eebe                                                                                     21 minutes ago      Exited              kubernetes-dashboard               6                   fb16694676013       kubernetes-dashboard-8694d4445c-bd674
6ac6d051b8452       a608c686bac93                                                                                     21 minutes ago      Exited              metrics-server                     7                   fae51eb7fc656       metrics-server-7c66d45ddc-xvkxw
432021a6d96db       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   21 minutes ago      Exited              copyutil                           3                   1b009003b14b9       argocd-dex-server-799769c4-hgx5t
4cd90620bbb1c       115053965e86b                                                                                     21 minutes ago      Running             dashboard-metrics-scraper          4                   5b7c1601f8c03       dashboard-metrics-scraper-7fd5cb4ddc-cwv26
f45639a7dc146       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   21 minutes ago      Running             argocd-application-controller      3                   17a72b94945b6       argocd-application-controller-0
b25698dafe977       5aa0bf4798fa2                                                                                     21 minutes ago      Exited              controller                         6                   0d562dc907919       ingress-nginx-controller-7c6974c4d8-2bjx2
9a96bb19196c3       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   22 minutes ago      Running             argocd-applicationset-controller   3                   5f8b3f3e18d0d       argocd-applicationset-controller-555c44bc74-b9zhg
90f250923e385       ff6a2c09fb663                                                                                     22 minutes ago      Exited              copyutil                           1                   c38399d250d3b       argocd-repo-server-855847b666-wsr8c
dcc0adb49851b       ff6a2c09fb663                                                                                     22 minutes ago      Exited              secret-init                        1                   9c43a2e0ea483       argocd-redis-77c9575655-lkhcs
6749a3101c729       ead0a4a53df89                                                                                     22 minutes ago      Running             coredns                            7                   c2564d8c748eb       coredns-5dd5756b68-kqfct
945dadf95371e       eec5dff0d2745                                                                                     23 minutes ago      Running             laravel-app                        4                   98ff2a57f2e8d       laravel-app-54c45994f6-4ghls
d466475bcc658       bfc896cf80fba                                                                                     23 minutes ago      Running             kube-proxy                         7                   9ee4f050bbe6d       kube-proxy-85xrx
917f3f68dddcd       10baa1ca17068                                                                                     23 minutes ago      Running             kube-controller-manager            10                  056c1c6ba7ae3       kube-controller-manager-minikube
14612090d8398       5374347291230                                                                                     24 minutes ago      Running             kube-apiserver                     7                   4d6f6c4867911       kube-apiserver-minikube
d452a80ceeef3       10baa1ca17068                                                                                     24 minutes ago      Exited              kube-controller-manager            9                   056c1c6ba7ae3       kube-controller-manager-minikube
04faedbf8d598       6d1b4fd1b182d                                                                                     24 minutes ago      Running             kube-scheduler                     7                   f124f358578dd       kube-scheduler-minikube
25f185e878c60       73deb9a3f7025                                                                                     24 minutes ago      Running             etcd                               7                   9b6d8eb67624e       etcd-minikube
ce4e34c1e69f9       httpd@sha256:3198c1839e1a875f8b83803083758a7635f1ae999f0601f30f2f3b8ce2ac99e3                     2 weeks ago         Exited              apache                             0                   e320b291709d3       apache
755e0c1bbee5a       redis@sha256:c9d92d840fd011c908f040592857c724ae6d877f2aba5c40ad963276507386b2                     2 weeks ago         Exited              redis                              2                   d2e92c92a03dc       argocd-redis-77c9575655-lkhcs
be7c29699707c       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   2 weeks ago         Exited              argocd-repo-server                 2                   c9fe721de1b10       argocd-repo-server-855847b666-wsr8c
069541ced82a0       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   2 weeks ago         Exited              argocd-applicationset-controller   2                   3f618078f3ff3       argocd-applicationset-controller-555c44bc74-b9zhg
d3b23193e1198       quay.io/argoproj/argocd@sha256:5233625223d3ff51f609353e155407da227b2d8defb125545deb6b652a5f5c8e   2 weeks ago         Exited              argocd-server                      2                   6b406785d06ff       argocd-server-85c8dc874f-hwzp6
a066703a00889       ead0a4a53df89                                                                                     2 weeks ago         Exited              coredns                            6                   d380ab1ded70b       coredns-5dd5756b68-kqfct
d3a976328c91a       eec5dff0d2745                                                                                     2 weeks ago         Exited              laravel-app                        3                   1a854d84aa475       laravel-app-54c45994f6-4ghls
f40b3946b93aa       73deb9a3f7025                                                                                     2 weeks ago         Exited              etcd                               6                   c6354ec08ff12       etcd-minikube
1b66d653ccac8       5374347291230                                                                                     2 weeks ago         Exited              kube-apiserver                     6                   9dd9e7c3b5f8b       kube-apiserver-minikube
7229096552dbf       6d1b4fd1b182d                                                                                     2 weeks ago         Exited              kube-scheduler                     6                   ea1cbab302d99       kube-scheduler-minikube
6467fe3fe1aca       1ebff0f9671bc                                                                                     9 months ago        Exited              patch                              1                   7b9b504776ebd       ingress-nginx-admission-patch-pd4dk
13e53be08e61b       1ebff0f9671bc                                                                                     9 months ago        Exited              create                             0                   0c1a6238fc4a7       ingress-nginx-admission-create-nnd8h

* 
* ==> controller_ingress [046975e21aab] <==
* W0910 15:28:58.350004       7 client_config.go:618] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
I0910 15:28:58.350221       7 main.go:205] "Creating API client" host="https://10.96.0.1:443"
I0910 15:29:01.107526       7 main.go:249] "Running in Kubernetes cluster" major="1" minor="28" git="v1.28.3" state="clean" commit="a8a1abc25cad87333840cd7d54be2efaf31a3177" platform="linux/amd64"
I0910 15:29:03.616927       7 main.go:101] "SSL fake certificate created" file="/etc/ingress-controller/ssl/default-fake-certificate.pem"
I0910 15:29:08.430815       7 ssl.go:536] "loading tls certificate" path="/usr/local/certificates/cert" key="/usr/local/certificates/key"
I0910 15:29:10.117060       7 nginx.go:260] "Starting NGINX Ingress controller"
I0910 15:29:10.382520       7 event.go:298] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"ingress-nginx-controller", UID:"be257a24-8cfd-46a7-a7c2-4ff000664cbf", APIVersion:"v1", ResourceVersion:"29978", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/ingress-nginx-controller
I0910 15:29:10.382571       7 event.go:298] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"tcp-services", UID:"81abf688-851a-4392-8e9c-927160fe7bcf", APIVersion:"v1", ResourceVersion:"29979", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/tcp-services
I0910 15:29:10.382581       7 event.go:298] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"udp-services", UID:"584180e2-9cfa-4894-890c-2b980cb2eaf2", APIVersion:"v1", ResourceVersion:"29980", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/udp-services
I0910 15:29:11.319080       7 store.go:440] "Found valid IngressClass" ingress="monografia/laravel-ingress" ingressclass="nginx"
I0910 15:29:11.319319       7 event.go:298] Event(v1.ObjectReference{Kind:"Ingress", Namespace:"monografia", Name:"laravel-ingress", UID:"99cc3ee9-3005-4923-b139-ef7253579048", APIVersion:"networking.k8s.io/v1", ResourceVersion:"93967", FieldPath:""}): type: 'Normal' reason: 'Sync' Scheduled for sync
I0910 15:29:11.415187       7 nginx.go:303] "Starting NGINX process"
I0910 15:29:11.415272       7 leaderelection.go:245] attempting to acquire leader lease ingress-nginx/ingress-nginx-leader...
I0910 15:29:11.415813       7 nginx.go:323] "Starting validation webhook" address=":8443" certPath="/usr/local/certificates/cert" keyPath="/usr/local/certificates/key"
I0910 15:29:11.521775       7 controller.go:190] "Configuration changes detected, backend reload required"
I0910 15:29:14.379365       7 leaderelection.go:255] successfully acquired lease ingress-nginx/ingress-nginx-leader
I0910 15:29:14.379431       7 status.go:84] "New leader elected" identity="ingress-nginx-controller-7c6974c4d8-2bjx2"
I0910 15:29:15.354354       7 status.go:219] "POD is not ready" pod="ingress-nginx/ingress-nginx-controller-7c6974c4d8-2bjx2" node="minikube"
I0910 15:29:16.038526       7 status.go:304] "updating Ingress status" namespace="monografia" ingress="laravel-ingress" currentValue=[{"ip":"192.168.49.2"}] newValue=[]
I0910 15:29:16.851399       7 event.go:298] Event(v1.ObjectReference{Kind:"Ingress", Namespace:"monografia", Name:"laravel-ingress", UID:"99cc3ee9-3005-4923-b139-ef7253579048", APIVersion:"networking.k8s.io/v1", ResourceVersion:"108344", FieldPath:""}): type: 'Normal' reason: 'Sync' Scheduled for sync
E0910 15:29:27.289112       7 controller.go:205] Unexpected failure reloading the backend:
exit status 1
2025/09/10 15:29:26 [notice] 26#26: signal process started
2025/09/10 15:29:26 [error] 26#26: invalid PID number "" in "/tmp/nginx/nginx.pid"
nginx: [error] invalid PID number "" in "/tmp/nginx/nginx.pid"
E0910 15:29:27.289153       7 queue.go:131] "requeuing" err=<
	exit status 1
	2025/09/10 15:29:26 [notice] 26#26: signal process started
	2025/09/10 15:29:26 [error] 26#26: invalid PID number "" in "/tmp/nginx/nginx.pid"
	nginx: [error] invalid PID number "" in "/tmp/nginx/nginx.pid"
 > key="initial-sync"
I0910 15:29:27.289283       7 controller.go:190] "Configuration changes detected, backend reload required"
I0910 15:29:27.289334       7 event.go:298] Event(v1.ObjectReference{Kind:"Pod", Namespace:"ingress-nginx", Name:"ingress-nginx-controller-7c6974c4d8-2bjx2", UID:"a700fdb7-e142-42b1-8f35-31b9bbdf72fb", APIVersion:"v1", ResourceVersion:"108310", FieldPath:""}): type: 'Warning' reason: 'RELOAD' Error reloading NGINX: exit status 1
2025/09/10 15:29:26 [notice] 26#26: signal process started
2025/09/10 15:29:26 [error] 26#26: invalid PID number "" in "/tmp/nginx/nginx.pid"
nginx: [error] invalid PID number "" in "/tmp/nginx/nginx.pid"
I0910 15:29:27.525777       7 controller.go:210] "Backend successfully reloaded"
I0910 15:29:27.526022       7 controller.go:221] "Initial sync, sleeping for 1 second"
I0910 15:29:27.526045       7 event.go:298] Event(v1.ObjectReference{Kind:"Pod", Namespace:"ingress-nginx", Name:"ingress-nginx-controller-7c6974c4d8-2bjx2", UID:"a700fdb7-e142-42b1-8f35-31b9bbdf72fb", APIVersion:"v1", ResourceVersion:"108310", FieldPath:""}): type: 'Normal' reason: 'RELOAD' NGINX reload triggered due to a change in configuration
W0910 15:29:28.692116       7 controller.go:241] Dynamic reconfiguration failed (retrying; 15 retries left): Post "http://127.0.0.1:10246/configuration/backends": dial tcp 127.0.0.1:10246: connect: connection refused
W0910 15:29:29.761146       7 controller.go:241] Dynamic reconfiguration failed (retrying; 14 retries left): Post "http://127.0.0.1:10246/configuration/backends": dial tcp 127.0.0.1:10246: connect: connection refused
W0910 15:29:31.083352       7 controller.go:241] Dynamic reconfiguration failed (retrying; 13 retries left): Post "http://127.0.0.1:10246/configuration/backends": dial tcp 127.0.0.1:10246: connect: connection refused
I0910 15:30:16.569602       7 status.go:304] "updating Ingress status" namespace="monografia" ingress="laravel-ingress" currentValue=null newValue=[{"ip":"192.168.49.2"}]
I0910 15:30:17.301683       7 event.go:298] Event(v1.ObjectReference{Kind:"Ingress", Namespace:"monografia", Name:"laravel-ingress", UID:"99cc3ee9-3005-4923-b139-ef7253579048", APIVersion:"networking.k8s.io/v1", ResourceVersion:"108440", FieldPath:""}): type: 'Normal' reason: 'Sync' Scheduled for sync
-------------------------------------------------------------------------------
NGINX Ingress controller
  Release:       v1.9.4
  Build:         846d251814a09d8a5d8d28e2e604bfc7749bcb49
  Repository:    https://github.com/kubernetes/ingress-nginx
  nginx version: nginx/1.21.6

-------------------------------------------------------------------------------


* 
* ==> controller_ingress [b25698dafe97] <==
* W0910 15:27:48.859713       7 client_config.go:618] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
I0910 15:27:48.859968       7 main.go:205] "Creating API client" host="https://10.96.0.1:443"
W0910 15:28:27.790890       7 main.go:246] Initial connection to the Kubernetes API server was retried 1 times.
I0910 15:28:27.790927       7 main.go:249] "Running in Kubernetes cluster" major="1" minor="28" git="v1.28.3" state="clean" commit="a8a1abc25cad87333840cd7d54be2efaf31a3177" platform="linux/amd64"
I0910 15:28:30.052431       7 main.go:101] "SSL fake certificate created" file="/etc/ingress-controller/ssl/default-fake-certificate.pem"
-------------------------------------------------------------------------------
NGINX Ingress controller
  Release:       v1.9.4
  Build:         846d251814a09d8a5d8d28e2e604bfc7749bcb49
  Repository:    https://github.com/kubernetes/ingress-nginx
  nginx version: nginx/1.21.6

-------------------------------------------------------------------------------


* 
* ==> coredns [6749a3101c72] <==
* [INFO] 10.244.0.75:37936 - 62936 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000437793s
[INFO] 10.244.0.75:58160 - 19879 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000180097s
[INFO] 10.244.0.75:57268 - 1997 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000117822s
[INFO] 10.244.0.75:59383 - 63103 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000104849s
[INFO] 10.244.0.75:35727 - 39701 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000164671s
[INFO] 10.244.0.75:49726 - 37549 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000076046s
[INFO] 10.244.0.75:56571 - 21749 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000134317s
[INFO] 10.244.0.75:58165 - 19432 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000208824s
[INFO] 10.244.0.75:46088 - 31580 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000325148s
[INFO] 10.244.0.75:45384 - 38708 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000081318s
[INFO] 10.244.0.75:54351 - 19490 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000132361s
[INFO] 10.244.0.75:55188 - 4866 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000076415s
[INFO] 10.244.0.75:43825 - 61206 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000122374s
[INFO] 10.244.0.75:37736 - 59979 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000276858s
[INFO] 10.244.0.75:33638 - 12857 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000421615s
[INFO] 10.244.0.75:58678 - 26838 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000268101s
[INFO] 10.244.0.75:38180 - 2287 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000133135s
[INFO] 10.244.0.75:55579 - 49216 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000162575s
[INFO] 10.244.0.75:49565 - 42897 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000464102s
[INFO] 10.244.0.75:34802 - 40438 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000101813s
[INFO] 10.244.0.75:55723 - 35141 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.00010476s
[INFO] 10.244.0.75:33411 - 21815 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.00007254s
[INFO] 10.244.0.75:45670 - 6941 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000171838s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.77262032s
[INFO] 10.244.0.75:46704 - 50810 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000299326s
[INFO] 10.244.0.75:47413 - 63623 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000472231s
[INFO] 10.244.0.75:57662 - 54272 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000245189s
[INFO] 10.244.0.75:34107 - 34086 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000303031s
[INFO] 10.244.0.75:56398 - 33666 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000086473s
[INFO] 10.244.0.75:53717 - 21256 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000151217s
[INFO] 10.244.0.75:49000 - 3383 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000093701s
[INFO] 10.244.0.75:35579 - 53352 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000129339s
[INFO] 10.244.0.79:36430 - 59474 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000120663s
[INFO] 10.244.0.79:50865 - 34293 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000067791s
[INFO] 10.244.0.79:51371 - 16212 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000113557s
[INFO] 10.244.0.79:53542 - 61333 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000191792s
[INFO] 10.244.0.79:52047 - 26881 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000122566s
[INFO] 10.244.0.79:57835 - 3955 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000152213s
[INFO] 10.244.0.79:48626 - 48131 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000105383s
[INFO] 10.244.0.79:58377 - 30467 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000184625s
[INFO] 10.244.0.75:46266 - 2866 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000091861s
[INFO] 10.244.0.75:38432 - 7202 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000154066s
[INFO] 10.244.0.75:55150 - 59103 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000225823s
[INFO] 10.244.0.75:50230 - 29357 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000145267s
[INFO] 10.244.0.75:59231 - 59839 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000281253s
[INFO] 10.244.0.75:53240 - 19973 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000178618s
[INFO] 10.244.0.75:47958 - 62374 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000335147s
[INFO] 10.244.0.75:45312 - 20871 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.00053844s
[INFO] 10.244.0.75:56875 - 42701 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000115765s
[INFO] 10.244.0.75:39905 - 31552 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000154012s
[INFO] 10.244.0.79:53037 - 27166 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000185424s
[INFO] 10.244.0.79:51384 - 11704 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000398088s
[INFO] 10.244.0.75:45574 - 54540 "AAAA IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 154 0.000342461s
[INFO] 10.244.0.75:59449 - 10066 "A IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 120 0.00049863s
[INFO] 10.244.0.82:41814 - 37763 "A IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 120 0.000083757s
[INFO] 10.244.0.82:54423 - 20441 "AAAA IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 154 0.000189592s
[INFO] 10.244.0.75:43357 - 3936 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000346615s
[INFO] 10.244.0.75:56613 - 60379 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000241342s
[INFO] 10.244.0.75:52606 - 25010 "A IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 120 0.00027576s
[INFO] 10.244.0.75:51930 - 17026 "AAAA IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 154 0.000392571s

* 
* ==> coredns [a066703a0088] <==
* [INFO] 10.244.0.59:34217 - 11121 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000213269s
[INFO] 10.244.0.59:56537 - 53244 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000583268s
[INFO] 10.244.0.65:52198 - 61526 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000213867s
[INFO] 10.244.0.65:58846 - 32154 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000364763s
[INFO] 10.244.0.65:52148 - 58200 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000215872s
[INFO] 10.244.0.65:41612 - 29413 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000306475s
[INFO] 10.244.0.65:59277 - 51906 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000202225s
[INFO] 10.244.0.65:35567 - 27826 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000299666s
[INFO] 10.244.0.65:41494 - 4538 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000201162s
[INFO] 10.244.0.65:36481 - 15950 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000249997s
[INFO] 10.244.0.59:56823 - 46159 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000085575s
[INFO] 10.244.0.59:42816 - 49575 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000131678s
[INFO] 10.244.0.59:40774 - 59761 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000270827s
[INFO] 10.244.0.59:50925 - 31494 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000291294s
[INFO] 10.244.0.59:33458 - 24700 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.00015624s
[INFO] 10.244.0.59:40913 - 36889 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000247395s
[INFO] 10.244.0.59:51669 - 47903 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000117771s
[INFO] 10.244.0.59:60914 - 19478 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000195168s
[INFO] 10.244.0.59:46867 - 35910 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000110028s
[INFO] 10.244.0.59:55274 - 33413 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000168164s
[INFO] 10.244.0.59:53884 - 30320 "A IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 120 0.00012093s
[INFO] 10.244.0.59:59986 - 35713 "AAAA IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 154 0.000165855s
[INFO] 10.244.0.59:44941 - 12573 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000183993s
[INFO] 10.244.0.59:53985 - 48611 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.00032778s
[INFO] 10.244.0.59:59734 - 15697 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.00020149s
[INFO] 10.244.0.59:52297 - 24759 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000611314s
[INFO] 10.244.0.59:41640 - 9556 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000102396s
[INFO] 10.244.0.59:56660 - 21585 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000144951s
[INFO] 10.244.0.59:43218 - 33514 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000071995s
[INFO] 10.244.0.59:35737 - 55739 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000114071s
[INFO] 10.244.0.59:36945 - 57301 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000048826s
[INFO] 10.244.0.59:60467 - 52789 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000060117s
[INFO] 10.244.0.61:54367 - 48284 "A IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 120 0.000082667s
[INFO] 10.244.0.61:47892 - 37217 "AAAA IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 154 0.000136074s
[INFO] 10.244.0.65:35436 - 5638 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000236525s
[INFO] 10.244.0.65:39016 - 20446 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.035040849s
[INFO] 10.244.0.59:50079 - 10346 "A IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 120 0.000305349s
[INFO] 10.244.0.59:49270 - 30030 "AAAA IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 154 0.000526728s
[INFO] 10.244.0.59:41213 - 17659 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.109704273s
[INFO] 10.244.0.59:35511 - 40057 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.109795472s
[INFO] 10.244.0.61:58396 - 58083 "AAAA IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 154 0.00037164s
[INFO] 10.244.0.61:41276 - 3469 "A IN argocd-repo-server.argocd.svc.cluster.local. udp 72 false 1232" NOERROR qr,aa,rd 120 0.000589272s
[INFO] 10.244.0.69:44339 - 34840 "A IN deb.debian.org.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000248951s
[INFO] 10.244.0.69:54849 - 42349 "A IN deb.debian.org.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.009914313s
[INFO] 10.244.0.69:40175 - 16517 "A IN deb.debian.org.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000228756s
[INFO] 10.244.0.69:47169 - 18448 "A IN deb.debian.org. udp 32 false 512" NOERROR qr,rd,ra 244 0.340426183s
[INFO] 10.244.0.69:40331 - 5157 "A IN deb.debian.org.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.000109284s
[INFO] 10.244.0.69:53255 - 11783 "A IN deb.debian.org.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.000040047s
[INFO] 10.244.0.69:52429 - 48937 "A IN deb.debian.org.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000064337s
[INFO] 10.244.0.69:51706 - 19737 "A IN deb.debian.org. udp 32 false 512" NOERROR qr,aa,rd,ra 244 0.000064776s
[INFO] 10.244.0.59:49873 - 32664 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000608815s
[INFO] 10.244.0.59:59264 - 31976 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000916937s
[INFO] 10.244.0.59:57324 - 48204 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000203234s
[INFO] 10.244.0.59:58011 - 58745 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000233132s
[INFO] 10.244.0.59:56516 - 47199 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000550886s
[INFO] 10.244.0.59:56125 - 58902 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000752843s
[INFO] 10.244.0.59:41758 - 18445 "A IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 108 0.000128797s
[INFO] 10.244.0.59:41037 - 21619 "AAAA IN argocd-redis.argocd.svc.cluster.local. udp 66 false 1232" NOERROR qr,aa,rd 148 0.000193955s
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=8220a6eb95f0a4d75f7f2d7b14cef975f050512d
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2024_10_17T21_44_21_0700
                    minikube.k8s.io/version=v1.32.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Fri, 18 Oct 2024 01:44:10 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 10 Sep 2025 15:49:14 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 10 Sep 2025 15:46:35 +0000   Fri, 18 Oct 2024 01:44:08 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 10 Sep 2025 15:46:35 +0000   Fri, 18 Oct 2024 01:44:08 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 10 Sep 2025 15:46:35 +0000   Fri, 18 Oct 2024 01:44:08 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 10 Sep 2025 15:46:35 +0000   Fri, 18 Oct 2024 01:44:20 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  514937084Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             7996960Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  514937084Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             7996960Ki
  pods:               110
System Info:
  Machine ID:                 5f44e582789f42f783d7c413f00d56b1
  System UUID:                2b72c12c-4f6b-41fd-9b53-fe516c2fd8cf
  Boot ID:                    c1590dcc-a6bd-4afd-8d96-e8db7ff5847f
  Kernel Version:             6.12.10-76061203-generic
  OS Image:                   Ubuntu 22.04.3 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://24.0.7
  Kubelet Version:            v1.28.3
  Kube-Proxy Version:         v1.28.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (22 in total)
  Namespace                   Name                                                 CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                                 ------------  ----------  ---------------  -------------  ---
  argocd                      argocd-application-controller-0                      0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         276d
  argocd                      argocd-applicationset-controller-555c44bc74-b9zhg    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         276d
  argocd                      argocd-dex-server-799769c4-hgx5t                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         276d
  argocd                      argocd-notifications-controller-5fddcdc68b-pzkwc     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         276d
  argocd                      argocd-redis-77c9575655-lkhcs                        0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         276d
  argocd                      argocd-repo-server-855847b666-wsr8c                  0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         276d
  argocd                      argocd-server-85c8dc874f-hwzp6                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         276d
  default                     apache                                               0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         19d
  default                     web-d-55bd745fcd-69bvt                               0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3m38s
  default                     web-d-55bd745fcd-dmmqr                               0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         3m38s
  ingress-nginx               ingress-nginx-controller-7c6974c4d8-2bjx2            100m (2%!)(MISSING)     0 (0%!)(MISSING)      90Mi (1%!)(MISSING)        0 (0%!)(MISSING)         290d
  kube-system                 coredns-5dd5756b68-kqfct                             100m (2%!)(MISSING)     0 (0%!)(MISSING)      70Mi (0%!)(MISSING)        170Mi (2%!)(MISSING)     327d
  kube-system                 etcd-minikube                                        100m (2%!)(MISSING)     0 (0%!)(MISSING)      100Mi (1%!)(MISSING)       0 (0%!)(MISSING)         327d
  kube-system                 kube-apiserver-minikube                              250m (6%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         327d
  kube-system                 kube-controller-manager-minikube                     200m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         327d
  kube-system                 kube-proxy-85xrx                                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         327d
  kube-system                 kube-scheduler-minikube                              100m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         327d
  kube-system                 metrics-server-7c66d45ddc-xvkxw                      100m (2%!)(MISSING)     0 (0%!)(MISSING)      200Mi (2%!)(MISSING)       0 (0%!)(MISSING)         277d
  kube-system                 storage-provisioner                                  0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         327d
  kubernetes-dashboard        dashboard-metrics-scraper-7fd5cb4ddc-cwv26           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         277d
  kubernetes-dashboard        kubernetes-dashboard-8694d4445c-bd674                0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         277d
  monografia                  laravel-app-54c45994f6-4ghls                         0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         290d
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                950m (23%!)(MISSING)  0 (0%!)(MISSING)
  memory             460Mi (5%!)(MISSING)  170Mi (2%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From             Message
  ----    ------                   ----               ----             -------
  Normal  Starting                 21m                kube-proxy       
  Normal  Starting                 25m                kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  25m                kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  25m (x8 over 25m)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    25m (x8 over 25m)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     25m (x7 over 25m)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  RegisteredNode           21m                node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [Sep10 11:08] x86/cpu: SGX disabled or unsupported by BIOS.
[  +0.380675] usb: port power management may be unreliable
[  +0.002177] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[  +0.000121] platform eisa.0: EISA: Cannot allocate resource for mainboard
[  +0.000003] platform eisa.0: Cannot allocate resource for EISA slot 1
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 2
[  +0.000001] platform eisa.0: Cannot allocate resource for EISA slot 3
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 4
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 5
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 6
[  +0.000001] platform eisa.0: Cannot allocate resource for EISA slot 7
[  +0.000002] platform eisa.0: Cannot allocate resource for EISA slot 8
[  +7.381739] r8169 0000:02:00.0: can't disable ASPM; OS doesn't have ASPM control
[  +2.740156] system76_acpi: loading out-of-tree module taints kernel.
[  +6.895695] block sda: the capability attribute has been deprecated.
[  +0.229958] systemd[1]: Configuration file /run/systemd/system/netplan-wpa-wlp4s0.service is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
[  +0.001988] systemd[1]: Configuration file /run/systemd/system/netplan-ovs-cleanup.service is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.
[  +0.302334] systemd[1]: /lib/systemd/system/snapd.service:23: Unknown key name 'RestartMode' in section 'Service', ignoring.
[  +5.111204] resource: resource sanity check: requesting [mem 0x00000000fdffe800-0x00000000fe0007ff], which spans more than pnp 00:07 [mem 0xfdb00000-0xfdffffff]
[  +0.000008] caller get_primary_reg_base+0x4f/0xb0 [intel_pmc_core] mapping multiple BARs
[  +5.081667] FAT-fs (sda1): Volume was not properly unmounted. Some data may be corrupt. Please run fsck.
[Sep10 11:10] kauditd_printk_skb: 34 callbacks suppressed
[ +29.780977] VBoxNetFlt: Successfully started.
[  +0.219432] VBoxNetAdp: Successfully started.
[Sep10 12:05] usb 1-5.1: device descriptor read/64, error -32
[Sep10 12:07] warning: `kdeconnectd' uses wireless extensions which will stop working for Wi-Fi 7 hardware; use nl80211
[ +11.115485] ntfs3(sdc1): volume is dirty and "force" flag is not set!

* 
* ==> etcd [25f185e878c6] <==
* {"level":"warn","ts":"2025-09-10T15:45:39.443668Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-09-10T15:45:39.010748Z","time spent":"432.91182ms","remote":"127.0.0.1:59262","response type":"/etcdserverpb.KV/Range","request count":0,"request size":67,"response count":1,"response size":1136,"request content":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" "}
{"level":"info","ts":"2025-09-10T15:45:39.981045Z","caller":"traceutil/trace.go:171","msg":"trace[1736970148] transaction","detail":"{read_only:false; response_revision:109565; number_of_response:1; }","duration":"221.768278ms","start":"2025-09-10T15:45:39.759263Z","end":"2025-09-10T15:45:39.981031Z","steps":["trace[1736970148] 'process raft request'  (duration: 221.671494ms)"],"step_count":1}
{"level":"warn","ts":"2025-09-10T15:45:40.204873Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"101.759551ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/secrets/\" range_end:\"/registry/secrets0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-09-10T15:45:40.204939Z","caller":"traceutil/trace.go:171","msg":"trace[2033051457] range","detail":"{range_begin:/registry/secrets/; range_end:/registry/secrets0; response_count:0; response_revision:109565; }","duration":"148.831386ms","start":"2025-09-10T15:45:40.056092Z","end":"2025-09-10T15:45:40.204923Z","steps":["trace[2033051457] 'count revisions from in-memory index tree'  (duration: 101.525008ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:40.295151Z","caller":"traceutil/trace.go:171","msg":"trace[946588121] linearizableReadLoop","detail":"{readStateIndex:134356; appliedIndex:134355; }","duration":"105.210271ms","start":"2025-09-10T15:45:40.189921Z","end":"2025-09-10T15:45:40.295131Z","steps":["trace[946588121] 'read index received'  (duration: 105.000648ms)","trace[946588121] 'applied index is now lower than readState.Index'  (duration: 208.508¬µs)"],"step_count":2}
{"level":"warn","ts":"2025-09-10T15:45:40.29527Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"105.342655ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/minions/\" range_end:\"/registry/minions0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-09-10T15:45:40.295311Z","caller":"traceutil/trace.go:171","msg":"trace[966289704] range","detail":"{range_begin:/registry/minions/; range_end:/registry/minions0; response_count:0; response_revision:109566; }","duration":"105.405203ms","start":"2025-09-10T15:45:40.189896Z","end":"2025-09-10T15:45:40.295301Z","steps":["trace[966289704] 'agreement among raft nodes before linearized reading'  (duration: 105.314859ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:40.295472Z","caller":"traceutil/trace.go:171","msg":"trace[1838407186] transaction","detail":"{read_only:false; response_revision:109566; number_of_response:1; }","duration":"133.566363ms","start":"2025-09-10T15:45:40.161887Z","end":"2025-09-10T15:45:40.295454Z","steps":["trace[1838407186] 'process raft request'  (duration: 133.104881ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:44.041095Z","caller":"traceutil/trace.go:171","msg":"trace[1578449302] transaction","detail":"{read_only:false; response_revision:109595; number_of_response:1; }","duration":"130.659267ms","start":"2025-09-10T15:45:43.910408Z","end":"2025-09-10T15:45:44.041067Z","steps":["trace[1578449302] 'process raft request'  (duration: 130.604987ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:44.040949Z","caller":"traceutil/trace.go:171","msg":"trace[194978014] transaction","detail":"{read_only:false; response_revision:109590; number_of_response:1; }","duration":"138.755746ms","start":"2025-09-10T15:45:43.902151Z","end":"2025-09-10T15:45:44.040907Z","steps":["trace[194978014] 'process raft request'  (duration: 77.687435ms)","trace[194978014] 'compare'  (duration: 60.671859ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:45:44.041311Z","caller":"traceutil/trace.go:171","msg":"trace[849347607] transaction","detail":"{read_only:false; response_revision:109593; number_of_response:1; }","duration":"136.415298ms","start":"2025-09-10T15:45:43.904865Z","end":"2025-09-10T15:45:44.04128Z","steps":["trace[849347607] 'process raft request'  (duration: 136.019028ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:44.041495Z","caller":"traceutil/trace.go:171","msg":"trace[1604083642] transaction","detail":"{read_only:false; response_revision:109594; number_of_response:1; }","duration":"131.903921ms","start":"2025-09-10T15:45:43.909565Z","end":"2025-09-10T15:45:44.041469Z","steps":["trace[1604083642] 'process raft request'  (duration: 131.395101ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:44.041741Z","caller":"traceutil/trace.go:171","msg":"trace[1596903902] transaction","detail":"{read_only:false; response_revision:109591; number_of_response:1; }","duration":"138.675769ms","start":"2025-09-10T15:45:43.903043Z","end":"2025-09-10T15:45:44.041719Z","steps":["trace[1596903902] 'process raft request'  (duration: 137.626172ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:44.041975Z","caller":"traceutil/trace.go:171","msg":"trace[1020481003] transaction","detail":"{read_only:false; response_revision:109592; number_of_response:1; }","duration":"137.318524ms","start":"2025-09-10T15:45:43.904635Z","end":"2025-09-10T15:45:44.041953Z","steps":["trace[1020481003] 'process raft request'  (duration: 136.114874ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:45.803736Z","caller":"traceutil/trace.go:171","msg":"trace[1344422766] transaction","detail":"{read_only:false; response_revision:109605; number_of_response:1; }","duration":"116.013645ms","start":"2025-09-10T15:45:45.68771Z","end":"2025-09-10T15:45:45.803724Z","steps":["trace[1344422766] 'process raft request'  (duration: 115.916991ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:47.661054Z","caller":"traceutil/trace.go:171","msg":"trace[37868445] transaction","detail":"{read_only:false; response_revision:109607; number_of_response:1; }","duration":"179.019794ms","start":"2025-09-10T15:45:47.482002Z","end":"2025-09-10T15:45:47.661021Z","steps":["trace[37868445] 'process raft request'  (duration: 97.883857ms)","trace[37868445] 'compare'  (duration: 80.995561ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:45:49.90684Z","caller":"traceutil/trace.go:171","msg":"trace[420206936] transaction","detail":"{read_only:false; response_revision:109613; number_of_response:1; }","duration":"122.091646ms","start":"2025-09-10T15:45:49.784718Z","end":"2025-09-10T15:45:49.906809Z","steps":["trace[420206936] 'process raft request'  (duration: 121.914176ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:45:58.267536Z","caller":"traceutil/trace.go:171","msg":"trace[1217738678] transaction","detail":"{read_only:false; response_revision:109634; number_of_response:1; }","duration":"100.042064ms","start":"2025-09-10T15:45:58.167462Z","end":"2025-09-10T15:45:58.267504Z","steps":["trace[1217738678] 'process raft request'  (duration: 99.796693ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:02.420924Z","caller":"traceutil/trace.go:171","msg":"trace[948674120] transaction","detail":"{read_only:false; response_revision:109637; number_of_response:1; }","duration":"112.520227ms","start":"2025-09-10T15:46:02.308387Z","end":"2025-09-10T15:46:02.420907Z","steps":["trace[948674120] 'process raft request'  (duration: 112.160059ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:05.614305Z","caller":"traceutil/trace.go:171","msg":"trace[1809693561] transaction","detail":"{read_only:false; response_revision:109643; number_of_response:1; }","duration":"455.095191ms","start":"2025-09-10T15:46:05.159196Z","end":"2025-09-10T15:46:05.614291Z","steps":["trace[1809693561] 'process raft request'  (duration: 428.521664ms)","trace[1809693561] 'compare'  (duration: 26.511928ms)"],"step_count":2}
{"level":"warn","ts":"2025-09-10T15:46:05.614385Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"224.924489ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/default/web-d-55bd745fcd-69bvt\" ","response":"range_response_count:1 size:2777"}
{"level":"warn","ts":"2025-09-10T15:46:05.614392Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-09-10T15:46:05.159185Z","time spent":"455.158727ms","remote":"127.0.0.1:59140","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":700,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/default/web-d-55bd745fcd-dmmqr.1863f65ae0ba782c\" mod_revision:109614 > success:<request_put:<key:\"/registry/events/default/web-d-55bd745fcd-dmmqr.1863f65ae0ba782c\" value_size:618 lease:8128039877104828619 >> failure:<request_range:<key:\"/registry/events/default/web-d-55bd745fcd-dmmqr.1863f65ae0ba782c\" > >"}
{"level":"info","ts":"2025-09-10T15:46:05.614407Z","caller":"traceutil/trace.go:171","msg":"trace[641476586] range","detail":"{range_begin:/registry/pods/default/web-d-55bd745fcd-69bvt; range_end:; response_count:1; response_revision:109643; }","duration":"224.955105ms","start":"2025-09-10T15:46:05.389448Z","end":"2025-09-10T15:46:05.614403Z","steps":["trace[641476586] 'agreement among raft nodes before linearized reading'  (duration: 224.882425ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:05.614304Z","caller":"traceutil/trace.go:171","msg":"trace[142335803] linearizableReadLoop","detail":"{readStateIndex:134440; appliedIndex:134439; }","duration":"224.821055ms","start":"2025-09-10T15:46:05.389469Z","end":"2025-09-10T15:46:05.61429Z","steps":["trace[142335803] 'read index received'  (duration: 198.241912ms)","trace[142335803] 'applied index is now lower than readState.Index'  (duration: 26.578651ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:46:08.159951Z","caller":"traceutil/trace.go:171","msg":"trace[1484343809] transaction","detail":"{read_only:false; response_revision:109649; number_of_response:1; }","duration":"127.87195ms","start":"2025-09-10T15:46:08.032059Z","end":"2025-09-10T15:46:08.159931Z","steps":["trace[1484343809] 'process raft request'  (duration: 114.238178ms)","trace[1484343809] 'compare'  (duration: 13.469359ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:46:12.129552Z","caller":"traceutil/trace.go:171","msg":"trace[1601093723] transaction","detail":"{read_only:false; response_revision:109654; number_of_response:1; }","duration":"475.390208ms","start":"2025-09-10T15:46:11.65415Z","end":"2025-09-10T15:46:12.12954Z","steps":["trace[1601093723] 'process raft request'  (duration: 475.24003ms)"],"step_count":1}
{"level":"warn","ts":"2025-09-10T15:46:12.129652Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-09-10T15:46:11.654137Z","time spent":"475.461872ms","remote":"127.0.0.1:59372","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":486,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" mod_revision:109640 > success:<request_put:<key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" value_size:427 >> failure:<request_range:<key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" > >"}
{"level":"info","ts":"2025-09-10T15:46:19.518542Z","caller":"traceutil/trace.go:171","msg":"trace[434971777] transaction","detail":"{read_only:false; response_revision:109661; number_of_response:1; }","duration":"113.757218ms","start":"2025-09-10T15:46:19.404742Z","end":"2025-09-10T15:46:19.518499Z","steps":["trace[434971777] 'process raft request'  (duration: 74.820253ms)","trace[434971777] 'compare'  (duration: 38.139453ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:46:30.271339Z","caller":"traceutil/trace.go:171","msg":"trace[2032419678] transaction","detail":"{read_only:false; response_revision:109677; number_of_response:1; }","duration":"108.890244ms","start":"2025-09-10T15:46:30.162419Z","end":"2025-09-10T15:46:30.271309Z","steps":["trace[2032419678] 'process raft request'  (duration: 108.714546ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:34.688374Z","caller":"traceutil/trace.go:171","msg":"trace[1509204328] transaction","detail":"{read_only:false; response_revision:109685; number_of_response:1; }","duration":"278.255624ms","start":"2025-09-10T15:46:34.410101Z","end":"2025-09-10T15:46:34.688357Z","steps":["trace[1509204328] 'process raft request'  (duration: 278.030396ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:34.892142Z","caller":"traceutil/trace.go:171","msg":"trace[1170900928] transaction","detail":"{read_only:false; response_revision:109686; number_of_response:1; }","duration":"115.236229ms","start":"2025-09-10T15:46:34.776871Z","end":"2025-09-10T15:46:34.892108Z","steps":["trace[1170900928] 'process raft request'  (duration: 28.313292ms)","trace[1170900928] 'compare'  (duration: 86.786145ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:46:35.996839Z","caller":"traceutil/trace.go:171","msg":"trace[535608443] transaction","detail":"{read_only:false; response_revision:109688; number_of_response:1; }","duration":"103.100829ms","start":"2025-09-10T15:46:35.893659Z","end":"2025-09-10T15:46:35.99676Z","steps":["trace[535608443] 'process raft request'  (duration: 102.906281ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:38.34194Z","caller":"traceutil/trace.go:171","msg":"trace[729616303] linearizableReadLoop","detail":"{readStateIndex:134495; appliedIndex:134494; }","duration":"266.823477ms","start":"2025-09-10T15:46:38.075105Z","end":"2025-09-10T15:46:38.341929Z","steps":["trace[729616303] 'read index received'  (duration: 254.774107ms)","trace[729616303] 'applied index is now lower than readState.Index'  (duration: 12.048791ms)"],"step_count":2}
{"level":"warn","ts":"2025-09-10T15:46:38.342033Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"266.940784ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/192.168.49.2\" ","response":"range_response_count:1 size:134"}
{"level":"info","ts":"2025-09-10T15:46:38.342052Z","caller":"traceutil/trace.go:171","msg":"trace[407851956] range","detail":"{range_begin:/registry/masterleases/192.168.49.2; range_end:; response_count:1; response_revision:109691; }","duration":"266.976837ms","start":"2025-09-10T15:46:38.07507Z","end":"2025-09-10T15:46:38.342047Z","steps":["trace[407851956] 'agreement among raft nodes before linearized reading'  (duration: 266.90394ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:38.342137Z","caller":"traceutil/trace.go:171","msg":"trace[956401748] transaction","detail":"{read_only:false; response_revision:109691; number_of_response:1; }","duration":"426.038008ms","start":"2025-09-10T15:46:37.916089Z","end":"2025-09-10T15:46:38.342127Z","steps":["trace[956401748] 'process raft request'  (duration: 413.817266ms)","trace[956401748] 'compare'  (duration: 11.955405ms)"],"step_count":2}
{"level":"warn","ts":"2025-09-10T15:46:38.342196Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-09-10T15:46:37.916077Z","time spent":"426.08283ms","remote":"127.0.0.1:59140","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":700,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/default/web-d-55bd745fcd-dmmqr.1863f65ae0ba782c\" mod_revision:109643 > success:<request_put:<key:\"/registry/events/default/web-d-55bd745fcd-dmmqr.1863f65ae0ba782c\" value_size:618 lease:8128039877104829112 >> failure:<request_range:<key:\"/registry/events/default/web-d-55bd745fcd-dmmqr.1863f65ae0ba782c\" > >"}
{"level":"info","ts":"2025-09-10T15:46:41.573165Z","caller":"traceutil/trace.go:171","msg":"trace[861990350] transaction","detail":"{read_only:false; response_revision:109696; number_of_response:1; }","duration":"246.994738ms","start":"2025-09-10T15:46:41.326153Z","end":"2025-09-10T15:46:41.573148Z","steps":["trace[861990350] 'process raft request'  (duration: 246.742206ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:46:46.549747Z","caller":"traceutil/trace.go:171","msg":"trace[867015520] linearizableReadLoop","detail":"{readStateIndex:134507; appliedIndex:134506; }","duration":"124.823198ms","start":"2025-09-10T15:46:46.424912Z","end":"2025-09-10T15:46:46.549735Z","steps":["trace[867015520] 'read index received'  (duration: 114.601293ms)","trace[867015520] 'applied index is now lower than readState.Index'  (duration: 10.221346ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:46:46.549816Z","caller":"traceutil/trace.go:171","msg":"trace[447054578] transaction","detail":"{read_only:false; response_revision:109701; number_of_response:1; }","duration":"144.912872ms","start":"2025-09-10T15:46:46.404891Z","end":"2025-09-10T15:46:46.549804Z","steps":["trace[447054578] 'process raft request'  (duration: 134.66323ms)","trace[447054578] 'compare'  (duration: 10.126069ms)"],"step_count":2}
{"level":"warn","ts":"2025-09-10T15:46:46.549831Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"124.926391ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/default/web-d-55bd745fcd-69bvt.1863f65b8bde0214\" ","response":"range_response_count:1 size:722"}
{"level":"info","ts":"2025-09-10T15:46:46.549854Z","caller":"traceutil/trace.go:171","msg":"trace[639410683] range","detail":"{range_begin:/registry/events/default/web-d-55bd745fcd-69bvt.1863f65b8bde0214; range_end:; response_count:1; response_revision:109701; }","duration":"124.960784ms","start":"2025-09-10T15:46:46.424887Z","end":"2025-09-10T15:46:46.549848Z","steps":["trace[639410683] 'agreement among raft nodes before linearized reading'  (duration: 124.896388ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:47:10.306529Z","caller":"traceutil/trace.go:171","msg":"trace[724344451] transaction","detail":"{read_only:false; response_revision:109734; number_of_response:1; }","duration":"108.732658ms","start":"2025-09-10T15:47:10.19778Z","end":"2025-09-10T15:47:10.306513Z","steps":["trace[724344451] 'process raft request'  (duration: 108.633824ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:47:17.639972Z","caller":"traceutil/trace.go:171","msg":"trace[1490245564] transaction","detail":"{read_only:false; response_revision:109743; number_of_response:1; }","duration":"233.748697ms","start":"2025-09-10T15:47:17.40621Z","end":"2025-09-10T15:47:17.639959Z","steps":["trace[1490245564] 'process raft request'  (duration: 218.131262ms)","trace[1490245564] 'compare'  (duration: 15.557371ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:47:56.89653Z","caller":"traceutil/trace.go:171","msg":"trace[462777372] linearizableReadLoop","detail":"{readStateIndex:134616; appliedIndex:134615; }","duration":"144.956669ms","start":"2025-09-10T15:47:56.751562Z","end":"2025-09-10T15:47:56.896518Z","steps":["trace[462777372] 'read index received'  (duration: 131.302195ms)","trace[462777372] 'applied index is now lower than readState.Index'  (duration: 13.653613ms)"],"step_count":2}
{"level":"warn","ts":"2025-09-10T15:47:56.896623Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"145.063575ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/\" range_end:\"/registry/pods0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-09-10T15:47:56.896645Z","caller":"traceutil/trace.go:171","msg":"trace[986823690] range","detail":"{range_begin:/registry/pods/; range_end:/registry/pods0; response_count:0; response_revision:109795; }","duration":"145.098743ms","start":"2025-09-10T15:47:56.751541Z","end":"2025-09-10T15:47:56.896639Z","steps":["trace[986823690] 'agreement among raft nodes before linearized reading'  (duration: 145.029289ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:47:56.89671Z","caller":"traceutil/trace.go:171","msg":"trace[350589505] transaction","detail":"{read_only:false; response_revision:109795; number_of_response:1; }","duration":"500.649352ms","start":"2025-09-10T15:47:56.396053Z","end":"2025-09-10T15:47:56.896703Z","steps":["trace[350589505] 'process raft request'  (duration: 486.842067ms)","trace[350589505] 'compare'  (duration: 13.472789ms)"],"step_count":2}
{"level":"warn","ts":"2025-09-10T15:47:56.89675Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-09-10T15:47:56.39604Z","time spent":"500.682177ms","remote":"127.0.0.1:59286","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":2631,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/pods/default/web-d-55bd745fcd-dmmqr\" mod_revision:109780 > success:<request_put:<key:\"/registry/pods/default/web-d-55bd745fcd-dmmqr\" value_size:2578 >> failure:<request_range:<key:\"/registry/pods/default/web-d-55bd745fcd-dmmqr\" > >"}
{"level":"info","ts":"2025-09-10T15:48:40.369288Z","caller":"traceutil/trace.go:171","msg":"trace[961974986] linearizableReadLoop","detail":"{readStateIndex:134666; appliedIndex:134665; }","duration":"117.047596ms","start":"2025-09-10T15:48:40.25221Z","end":"2025-09-10T15:48:40.369257Z","steps":["trace[961974986] 'read index received'  (duration: 116.799367ms)","trace[961974986] 'applied index is now lower than readState.Index'  (duration: 246.903¬µs)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:48:40.369419Z","caller":"traceutil/trace.go:171","msg":"trace[714989392] transaction","detail":"{read_only:false; response_revision:109836; number_of_response:1; }","duration":"138.814792ms","start":"2025-09-10T15:48:40.23057Z","end":"2025-09-10T15:48:40.369384Z","steps":["trace[714989392] 'process raft request'  (duration: 138.516546ms)"],"step_count":1}
{"level":"warn","ts":"2025-09-10T15:48:40.3695Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"117.272526ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/csistoragecapacities/\" range_end:\"/registry/csistoragecapacities0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-09-10T15:48:40.369596Z","caller":"traceutil/trace.go:171","msg":"trace[365941355] range","detail":"{range_begin:/registry/csistoragecapacities/; range_end:/registry/csistoragecapacities0; response_count:0; response_revision:109836; }","duration":"117.387935ms","start":"2025-09-10T15:48:40.252185Z","end":"2025-09-10T15:48:40.369573Z","steps":["trace[365941355] 'agreement among raft nodes before linearized reading'  (duration: 117.205711ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:48:44.560906Z","caller":"traceutil/trace.go:171","msg":"trace[1926830523] transaction","detail":"{read_only:false; response_revision:109841; number_of_response:1; }","duration":"106.316313ms","start":"2025-09-10T15:48:44.454559Z","end":"2025-09-10T15:48:44.560876Z","steps":["trace[1926830523] 'process raft request'  (duration: 106.109781ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:48:48.399373Z","caller":"traceutil/trace.go:171","msg":"trace[1709715936] transaction","detail":"{read_only:false; response_revision:109843; number_of_response:1; }","duration":"195.966629ms","start":"2025-09-10T15:48:48.203368Z","end":"2025-09-10T15:48:48.399335Z","steps":["trace[1709715936] 'process raft request'  (duration: 136.997496ms)","trace[1709715936] 'compare'  (duration: 58.783542ms)"],"step_count":2}
{"level":"info","ts":"2025-09-10T15:48:49.236063Z","caller":"traceutil/trace.go:171","msg":"trace[543614507] transaction","detail":"{read_only:false; response_revision:109844; number_of_response:1; }","duration":"626.616517ms","start":"2025-09-10T15:48:48.609434Z","end":"2025-09-10T15:48:49.23605Z","steps":["trace[543614507] 'process raft request'  (duration: 626.512967ms)"],"step_count":1}
{"level":"warn","ts":"2025-09-10T15:48:49.236155Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-09-10T15:48:48.609413Z","time spent":"626.700723ms","remote":"127.0.0.1:59262","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":1093,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:109842 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1020 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"info","ts":"2025-09-10T15:48:55.442845Z","caller":"traceutil/trace.go:171","msg":"trace[1207569605] transaction","detail":"{read_only:false; response_revision:109850; number_of_response:1; }","duration":"108.883207ms","start":"2025-09-10T15:48:55.33395Z","end":"2025-09-10T15:48:55.442833Z","steps":["trace[1207569605] 'process raft request'  (duration: 108.792338ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:49:14.370784Z","caller":"traceutil/trace.go:171","msg":"trace[1368919] transaction","detail":"{read_only:false; response_revision:109869; number_of_response:1; }","duration":"144.839507ms","start":"2025-09-10T15:49:14.225912Z","end":"2025-09-10T15:49:14.370752Z","steps":["trace[1368919] 'process raft request'  (duration: 144.634756ms)"],"step_count":1}
{"level":"info","ts":"2025-09-10T15:49:18.115275Z","caller":"traceutil/trace.go:171","msg":"trace[1583871315] transaction","detail":"{read_only:false; response_revision:109872; number_of_response:1; }","duration":"188.814395ms","start":"2025-09-10T15:49:17.926442Z","end":"2025-09-10T15:49:18.115256Z","steps":["trace[1583871315] 'process raft request'  (duration: 188.675816ms)"],"step_count":1}

* 
* ==> etcd [f40b3946b93a] <==
* {"level":"warn","ts":"2025-08-22T17:26:55.591768Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"143.770491ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-08-22T17:26:55.59182Z","caller":"traceutil/trace.go:171","msg":"trace[1097164862] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:107856; }","duration":"143.831664ms","start":"2025-08-22T17:26:55.447977Z","end":"2025-08-22T17:26:55.591809Z","steps":["trace[1097164862] 'range keys from in-memory index tree'  (duration: 143.692811ms)"],"step_count":1}
{"level":"info","ts":"2025-08-22T17:26:56.591794Z","caller":"traceutil/trace.go:171","msg":"trace[140863309] transaction","detail":"{read_only:false; response_revision:107857; number_of_response:1; }","duration":"143.669183ms","start":"2025-08-22T17:26:56.448096Z","end":"2025-08-22T17:26:56.591765Z","steps":["trace[140863309] 'process raft request'  (duration: 143.476917ms)"],"step_count":1}
{"level":"info","ts":"2025-08-22T17:26:58.344671Z","caller":"traceutil/trace.go:171","msg":"trace[2057147002] transaction","detail":"{read_only:false; response_revision:107858; number_of_response:1; }","duration":"121.977322ms","start":"2025-08-22T17:26:58.222658Z","end":"2025-08-22T17:26:58.344635Z","steps":["trace[2057147002] 'process raft request'  (duration: 121.777211ms)"],"step_count":1}
{"level":"info","ts":"2025-08-22T17:27:01.779087Z","caller":"traceutil/trace.go:171","msg":"trace[1436644602] transaction","detail":"{read_only:false; number_of_response:1; response_revision:107862; }","duration":"668.380968ms","start":"2025-08-22T17:27:01.110675Z","end":"2025-08-22T17:27:01.779056Z","steps":["trace[1436644602] 'process raft request'  (duration: 668.195137ms)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:02.549651Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:01.174375Z","time spent":"1.375271683s","remote":"127.0.0.1:46554","response type":"/etcdserverpb.KV/Txn","request count":0,"request size":0,"response count":0,"response size":0,"request content":""}
{"level":"warn","ts":"2025-08-22T17:27:02.54979Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"577.391006ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/kube-system/metrics-server-7c66d45ddc-xvkxw.185e1904c19746ee\" ","response":"","error":"context canceled"}
{"level":"info","ts":"2025-08-22T17:27:02.549836Z","caller":"traceutil/trace.go:171","msg":"trace[1850722130] range","detail":"{range_begin:/registry/events/kube-system/metrics-server-7c66d45ddc-xvkxw.185e1904c19746ee; range_end:; }","duration":"577.448667ms","start":"2025-08-22T17:27:01.972376Z","end":"2025-08-22T17:27:02.549825Z","steps":["trace[1850722130] 'agreement among raft nodes before linearized reading'  (duration: 577.09474ms)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:02.549866Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:01.972362Z","time spent":"577.49602ms","remote":"127.0.0.1:46396","response type":"/etcdserverpb.KV/Range","request count":0,"request size":79,"response count":0,"response size":0,"request content":"key:\"/registry/events/kube-system/metrics-server-7c66d45ddc-xvkxw.185e1904c19746ee\" "}
{"level":"warn","ts":"2025-08-22T17:27:03.434522Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"2.01020039s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"","error":"context deadline exceeded"}
{"level":"info","ts":"2025-08-22T17:27:03.434631Z","caller":"traceutil/trace.go:171","msg":"trace[1609893170] range","detail":"{range_begin:/registry/health; range_end:; }","duration":"2.010299832s","start":"2025-08-22T17:27:01.4243Z","end":"2025-08-22T17:27:03.4346Z","steps":["trace[1609893170] 'agreement among raft nodes before linearized reading'  (duration: 2.010196558s)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:03.434703Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:01.424287Z","time spent":"2.010398511s","remote":"127.0.0.1:46342","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":0,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2025-08-22T17:27:03.435027Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.504737618s","expected-duration":"100ms","prefix":"","request":"header:<ID:8128039454814293898 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/leases/kube-node-lease/minikube\" mod_revision:107853 > success:<request_put:<key:\"/registry/leases/kube-node-lease/minikube\" value_size:471 >> failure:<request_range:<key:\"/registry/leases/kube-node-lease/minikube\" > >>","response":"size:18"}
{"level":"info","ts":"2025-08-22T17:27:03.435088Z","caller":"traceutil/trace.go:171","msg":"trace[2026030977] linearizableReadLoop","detail":"{readStateIndex:132380; appliedIndex:132378; }","duration":"2.073092569s","start":"2025-08-22T17:27:01.361984Z","end":"2025-08-22T17:27:03.435077Z","steps":["trace[2026030977] 'read index received'  (duration: 416.889505ms)","trace[2026030977] 'applied index is now lower than readState.Index'  (duration: 1.656200516s)"],"step_count":2}
{"level":"warn","ts":"2025-08-22T17:27:03.435527Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"2.073578287s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/storageclasses/\" range_end:\"/registry/storageclasses0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-08-22T17:27:03.435549Z","caller":"traceutil/trace.go:171","msg":"trace[1472303009] range","detail":"{range_begin:/registry/storageclasses/; range_end:/registry/storageclasses0; response_count:0; response_revision:107863; }","duration":"2.07360132s","start":"2025-08-22T17:27:01.361942Z","end":"2025-08-22T17:27:03.435543Z","steps":["trace[1472303009] 'agreement among raft nodes before linearized reading'  (duration: 2.073565054s)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:03.435565Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:01.361923Z","time spent":"2.073638051s","remote":"127.0.0.1:46642","response type":"/etcdserverpb.KV/Range","request count":0,"request size":56,"response count":1,"response size":32,"request content":"key:\"/registry/storageclasses/\" range_end:\"/registry/storageclasses0\" count_only:true "}
{"level":"warn","ts":"2025-08-22T17:27:03.435669Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"913.360996ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" ","response":"range_response_count:1 size:505"}
{"level":"info","ts":"2025-08-22T17:27:03.435684Z","caller":"traceutil/trace.go:171","msg":"trace[1043723410] range","detail":"{range_begin:/registry/leases/ingress-nginx/ingress-nginx-leader; range_end:; response_count:1; response_revision:107863; }","duration":"913.376462ms","start":"2025-08-22T17:27:02.522303Z","end":"2025-08-22T17:27:03.43568Z","steps":["trace[1043723410] 'agreement among raft nodes before linearized reading'  (duration: 913.345712ms)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:03.435699Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:02.522291Z","time spent":"913.404655ms","remote":"127.0.0.1:46554","response type":"/etcdserverpb.KV/Range","request count":0,"request size":53,"response count":1,"response size":529,"request content":"key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" "}
{"level":"warn","ts":"2025-08-22T17:27:03.435872Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"315.1135ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/\" range_end:\"/registry/pods0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-08-22T17:27:03.435889Z","caller":"traceutil/trace.go:171","msg":"trace[12499694] range","detail":"{range_begin:/registry/pods/; range_end:/registry/pods0; response_count:0; response_revision:107863; }","duration":"315.130962ms","start":"2025-08-22T17:27:03.120752Z","end":"2025-08-22T17:27:03.435883Z","steps":["trace[12499694] 'agreement among raft nodes before linearized reading'  (duration: 315.099332ms)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:03.435902Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:03.120743Z","time spent":"315.155657ms","remote":"127.0.0.1:46482","response type":"/etcdserverpb.KV/Range","request count":0,"request size":36,"response count":23,"response size":32,"request content":"key:\"/registry/pods/\" range_end:\"/registry/pods0\" count_only:true "}
{"level":"warn","ts":"2025-08-22T17:27:03.436008Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"913.676937ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/ingress-nginx/\" range_end:\"/registry/pods/ingress-nginx0\" ","response":"range_response_count:3 size:13697"}
{"level":"info","ts":"2025-08-22T17:27:03.436023Z","caller":"traceutil/trace.go:171","msg":"trace[105486000] range","detail":"{range_begin:/registry/pods/ingress-nginx/; range_end:/registry/pods/ingress-nginx0; response_count:3; response_revision:107863; }","duration":"913.69169ms","start":"2025-08-22T17:27:02.522326Z","end":"2025-08-22T17:27:03.436018Z","steps":["trace[105486000] 'agreement among raft nodes before linearized reading'  (duration: 913.640909ms)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:03.436036Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:02.522291Z","time spent":"913.741792ms","remote":"127.0.0.1:46482","response type":"/etcdserverpb.KV/Range","request count":0,"request size":62,"response count":3,"response size":13721,"request content":"key:\"/registry/pods/ingress-nginx/\" range_end:\"/registry/pods/ingress-nginx0\" "}
{"level":"warn","ts":"2025-08-22T17:27:03.629785Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:01.110659Z","time spent":"668.525243ms","remote":"127.0.0.1:46354","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":39,"response count":0,"response size":44,"request content":"compare:<target:MOD key:\"/registry/masterleases/192.168.49.2\" mod_revision:107860 > success:<request_delete_range:<key:\"/registry/masterleases/192.168.49.2\" > > failure:<request_range:<key:\"/registry/masterleases/192.168.49.2\" > >"}
{"level":"info","ts":"2025-08-22T17:27:03.635936Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
WARNING: 2025/08/22 17:27:03 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
WARNING: 2025/08/22 17:27:03 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2025-08-22T17:27:04.838704Z","caller":"wal/wal.go:805","msg":"slow fdatasync","took":"1.221346783s","expected-duration":"1s"}
{"level":"warn","ts":"2025-08-22T17:27:04.840497Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"717.009202ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/\" range_end:\"/registry/services/endpoints0\" count_only:true ","response":"","error":"context canceled"}
{"level":"info","ts":"2025-08-22T17:27:04.840539Z","caller":"traceutil/trace.go:171","msg":"trace[1108306057] range","detail":"{range_begin:/registry/services/endpoints/; range_end:/registry/services/endpoints0; }","duration":"717.064633ms","start":"2025-08-22T17:27:04.123463Z","end":"2025-08-22T17:27:04.840528Z","steps":["trace[1108306057] 'agreement among raft nodes before linearized reading'  (duration: 717.00826ms)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:04.840571Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:04.123439Z","time spent":"717.123471ms","remote":"127.0.0.1:46466","response type":"/etcdserverpb.KV/Range","request count":0,"request size":64,"response count":0,"response size":0,"request content":"key:\"/registry/services/endpoints/\" range_end:\"/registry/services/endpoints0\" count_only:true "}
{"level":"warn","ts":"2025-08-22T17:27:04.840727Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.211015372s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/minions/minikube\" ","response":"","error":"context canceled"}
{"level":"info","ts":"2025-08-22T17:27:04.840753Z","caller":"traceutil/trace.go:171","msg":"trace[1952662528] range","detail":"{range_begin:/registry/minions/minikube; range_end:; }","duration":"1.211044374s","start":"2025-08-22T17:27:03.629702Z","end":"2025-08-22T17:27:04.840746Z","steps":["trace[1952662528] 'agreement among raft nodes before linearized reading'  (duration: 1.211014399s)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:04.840775Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:03.629693Z","time spent":"1.211075281s","remote":"127.0.0.1:46474","response type":"/etcdserverpb.KV/Range","request count":0,"request size":28,"response count":0,"response size":0,"request content":"key:\"/registry/minions/minikube\" "}
{"level":"warn","ts":"2025-08-22T17:27:04.841216Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.210491223s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"","error":"context canceled"}
{"level":"info","ts":"2025-08-22T17:27:04.841258Z","caller":"traceutil/trace.go:171","msg":"trace[2110158170] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; }","duration":"1.210534303s","start":"2025-08-22T17:27:03.630717Z","end":"2025-08-22T17:27:04.841252Z","steps":["trace[2110158170] 'agreement among raft nodes before linearized reading'  (duration: 1.210490438s)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:04.84128Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:03.630708Z","time spent":"1.21056605s","remote":"127.0.0.1:46466","response type":"/etcdserverpb.KV/Range","request count":0,"request size":49,"response count":0,"response size":0,"request content":"key:\"/registry/services/endpoints/default/kubernetes\" "}
WARNING: 2025/08/22 17:27:04 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2025-08-22T17:27:04.85904Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:03.617213Z","time spent":"1.241823421s","remote":"127.0.0.1:46554","response type":"/etcdserverpb.KV/Txn","request count":0,"request size":0,"response count":0,"response size":0,"request content":""}
{"level":"warn","ts":"2025-08-22T17:27:04.130731Z","caller":"etcdserver/v3_server.go:897","msg":"waiting for ReadIndex response took too long, retrying","sent-request-id":8128039454814293901,"retry-timeout":"500ms"}
{"level":"warn","ts":"2025-08-22T17:27:05.063513Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.035635038s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/default/nginx1\" ","response":"","error":"context canceled"}
{"level":"info","ts":"2025-08-22T17:27:05.063545Z","caller":"traceutil/trace.go:171","msg":"trace[808440196] range","detail":"{range_begin:/registry/pods/default/nginx1; range_end:; }","duration":"1.035680559s","start":"2025-08-22T17:27:04.027856Z","end":"2025-08-22T17:27:05.063536Z","steps":["trace[808440196] 'agreement among raft nodes before linearized reading'  (duration: 1.03563376s)"],"step_count":1}
{"level":"warn","ts":"2025-08-22T17:27:05.063569Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-08-22T17:27:04.027846Z","time spent":"1.035716181s","remote":"127.0.0.1:46482","response type":"/etcdserverpb.KV/Range","request count":0,"request size":31,"response count":0,"response size":0,"request content":"key:\"/registry/pods/default/nginx1\" "}
WARNING: 2025/08/22 17:27:05 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2025-08-22T17:27:06.375478Z","caller":"wal/wal.go:805","msg":"slow fdatasync","took":"1.312051679s","expected-duration":"1s"}
{"level":"info","ts":"2025-08-22T17:27:06.375973Z","caller":"embed/etcd.go:376","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}
{"level":"warn","ts":"2025-08-22T17:27:06.376523Z","caller":"embed/serve.go:212","msg":"stopping secure grpc server due to error","error":"accept tcp 127.0.0.1:2379: use of closed network connection"}
{"level":"warn","ts":"2025-08-22T17:27:06.693779Z","caller":"embed/serve.go:214","msg":"stopped secure grpc server due to error","error":"accept tcp 127.0.0.1:2379: use of closed network connection"}
{"level":"warn","ts":"2025-08-22T17:27:07.72939Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"2.889189737s","expected-duration":"100ms","prefix":"","request":"header:<ID:8128039454814293902 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" mod_revision:107856 > success:<request_put:<key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" value_size:427 >> failure:<request_range:<key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" > >>","response":"size:18"}
{"level":"info","ts":"2025-08-22T17:27:07.743409Z","caller":"traceutil/trace.go:171","msg":"trace[380583442] linearizableReadLoop","detail":"{readStateIndex:132381; appliedIndex:132380; }","duration":"4.113671953s","start":"2025-08-22T17:27:03.629722Z","end":"2025-08-22T17:27:07.743394Z","steps":["trace[380583442] 'read index received'  (duration: 1.433748934s)","trace[380583442] 'applied index is now lower than readState.Index'  (duration: 2.67992017s)"],"step_count":2}
{"level":"warn","ts":"2025-08-22T17:27:07.743458Z","caller":"etcdserver/v3_server.go:874","msg":"ignored out-of-date read index response; local node read indexes queueing up and waiting to be in sync with leader","sent-request-id":8128039454814293904,"received-request-id":8128039454814293901}
{"level":"warn","ts":"2025-08-22T17:27:07.844399Z","caller":"embed/serve.go:212","msg":"stopping secure grpc server due to error","error":"accept tcp 192.168.49.2:2379: use of closed network connection"}
{"level":"warn","ts":"2025-08-22T17:27:07.844454Z","caller":"embed/serve.go:214","msg":"stopped secure grpc server due to error","error":"accept tcp 192.168.49.2:2379: use of closed network connection"}
{"level":"info","ts":"2025-08-22T17:27:08.324927Z","caller":"etcdserver/server.go:1465","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"aec36adc501070cc","current-leader-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2025-08-22T17:27:10.756497Z","caller":"embed/etcd.go:579","msg":"stopping serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2025-08-22T17:27:10.756591Z","caller":"embed/etcd.go:584","msg":"stopped serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2025-08-22T17:27:10.756613Z","caller":"embed/etcd.go:378","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}

* 
* ==> kernel <==
*  15:49:22 up  4:41,  0 users,  load average: 1.57, 3.62, 5.59
Linux minikube 6.12.10-76061203-generic #202412060638~1753385872~22.04~dc2e00d SMP PREEMPT_DYNAMIC Thu J x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.3 LTS"

* 
* ==> kube-apiserver [14612090d839] <==
* Trace[677096937]: ---"Write to database call succeeded" len:154 658ms (15:44:09.977)
Trace[677096937]: [658.795944ms] [658.795944ms] END
I0910 15:44:10.451403       1 trace.go:236] Trace[436672508]: "Delete" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:1426b398-f504-4a99-a6fc-799adb136ab6,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/default/pods/web-d-55bd745fcd-vt6b9,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:DELETE (10-Sep-2025 15:44:09.063) (total time: 1387ms):
Trace[436672508]: ---"Object deleted from database" 480ms (15:44:10.451)
Trace[436672508]: [1.387493894s] [1.387493894s] END
I0910 15:44:12.056022       1 trace.go:236] Trace[1789074100]: "Get" accept:application/json, */*,audit-id:ffb7cafa-b734-4452-910c-e3eb3de3d596,client:192.168.49.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:GET (10-Sep-2025 15:44:11.373) (total time: 681ms):
Trace[1789074100]: ---"About to write a response" 681ms (15:44:12.055)
Trace[1789074100]: [681.984944ms] [681.984944ms] END
I0910 15:44:12.755690       1 trace.go:236] Trace[1234655166]: "Update" accept:application/json, */*,audit-id:3b761ddb-6a64-4884-b9cf-4ae39351509a,client:192.168.49.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (10-Sep-2025 15:44:12.057) (total time: 698ms):
Trace[1234655166]: ["GuaranteedUpdate etcd3" audit-id:3b761ddb-6a64-4884-b9cf-4ae39351509a,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 698ms (15:44:12.057)
Trace[1234655166]:  ---"Txn call completed" 697ms (15:44:12.754)]
Trace[1234655166]: [698.390308ms] [698.390308ms] END
I0910 15:44:13.501433       1 trace.go:236] Trace[996808688]: "Delete" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:a37ee994-02d7-40fe-b5b4-9f798fa57dd1,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/default/pods/web-d-55bd745fcd-sl6kf,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:DELETE (10-Sep-2025 15:44:10.853) (total time: 2648ms):
Trace[996808688]: ["GuaranteedUpdate etcd3" audit-id:a37ee994-02d7-40fe-b5b4-9f798fa57dd1,key:/pods/default/web-d-55bd745fcd-sl6kf,type:*core.Pod,resource:pods 2647ms (15:44:10.853)
Trace[996808688]:  ---"Txn call completed" 1200ms (15:44:12.054)]
Trace[996808688]: ---"Object deleted from database" 1446ms (15:44:13.501)
Trace[996808688]: [2.648362333s] [2.648362333s] END
I0910 15:44:14.363546       1 trace.go:236] Trace[426954460]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:e8aa3cee-7568-4551-9c4a-d7c9ca7127b4,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/default/pods/web-d-8666fdb685-ch7rv/status,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PATCH (10-Sep-2025 15:44:13.598) (total time: 764ms):
Trace[426954460]: ["GuaranteedUpdate etcd3" audit-id:e8aa3cee-7568-4551-9c4a-d7c9ca7127b4,key:/pods/default/web-d-8666fdb685-ch7rv,type:*core.Pod,resource:pods 764ms (15:44:13.599)
Trace[426954460]:  ---"Txn call completed" 760ms (15:44:14.363)]
Trace[426954460]: ---"Object stored in database" 761ms (15:44:14.363)
Trace[426954460]: [764.591115ms] [764.591115ms] END
I0910 15:44:15.469292       1 trace.go:236] Trace[325562589]: "Update" accept:application/json, */*,audit-id:6faf5116-3b1c-4c0a-94a7-4aaa6089f359,client:192.168.49.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (10-Sep-2025 15:44:14.759) (total time: 709ms):
Trace[325562589]: ["GuaranteedUpdate etcd3" audit-id:6faf5116-3b1c-4c0a-94a7-4aaa6089f359,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 709ms (15:44:14.760)
Trace[325562589]:  ---"Txn call completed" 708ms (15:44:15.469)]
Trace[325562589]: [709.260872ms] [709.260872ms] END
I0910 15:44:16.016959       1 trace.go:236] Trace[991082014]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:99fed3d5-fe55-44af-b51d-96d3cf490fb9,client:::1,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,user-agent:kube-apiserver/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PUT (10-Sep-2025 15:44:14.941) (total time: 1075ms):
Trace[991082014]: ["GuaranteedUpdate etcd3" audit-id:99fed3d5-fe55-44af-b51d-96d3cf490fb9,key:/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,type:*coordination.Lease,resource:leases.coordination.k8s.io 1075ms (15:44:14.941)
Trace[991082014]:  ---"Txn call completed" 1073ms (15:44:16.016)]
Trace[991082014]: [1.07536177s] [1.07536177s] END
I0910 15:44:18.784127       1 trace.go:236] Trace[1719526786]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/192.168.49.2,type:*v1.Endpoints,resource:apiServerIPInfo (10-Sep-2025 15:44:18.066) (total time: 717ms):
Trace[1719526786]: ---"initial value restored" 327ms (15:44:18.394)
Trace[1719526786]: ---"Transaction prepared" 115ms (15:44:18.510)
Trace[1719526786]: ---"Txn call completed" 273ms (15:44:18.784)
Trace[1719526786]: [717.111054ms] [717.111054ms] END
I0910 15:44:19.443752       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0910 15:45:02.379072       1 trace.go:236] Trace[1634794006]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:e666e925-41dd-4f84-81cc-36ba61fd1bf3,client:192.168.49.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/default/events/web-d-8666fdb685-nqfmp.1863f6460f7de652,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PATCH (10-Sep-2025 15:45:01.395) (total time: 983ms):
Trace[1634794006]: ["GuaranteedUpdate etcd3" audit-id:e666e925-41dd-4f84-81cc-36ba61fd1bf3,key:/events/default/web-d-8666fdb685-nqfmp.1863f6460f7de652,type:*core.Event,resource:events 983ms (15:45:01.395)
Trace[1634794006]:  ---"initial value restored" 227ms (15:45:01.623)
Trace[1634794006]:  ---"Txn call completed" 754ms (15:45:02.378)]
Trace[1634794006]: ---"Object stored in database" 754ms (15:45:02.378)
Trace[1634794006]: [983.480625ms] [983.480625ms] END
I0910 15:45:19.447481       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0910 15:45:19.810629       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0910 15:45:20.226052       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0910 15:45:20.226359       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0910 15:45:43.907379       1 alloc.go:330] "allocated clusterIPs" service="default/web-svc" clusterIPs={"IPv4":"10.96.247.150"}
I0910 15:46:19.443242       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0910 15:47:19.446590       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0910 15:47:56.897303       1 trace.go:236] Trace[2059295943]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:c3e13d8a-d652-4114-8f2d-b0016f1f984b,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/default/pods/web-d-55bd745fcd-dmmqr/status,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PATCH (10-Sep-2025 15:47:56.393) (total time: 503ms):
Trace[2059295943]: ["GuaranteedUpdate etcd3" audit-id:c3e13d8a-d652-4114-8f2d-b0016f1f984b,key:/pods/default/web-d-55bd745fcd-dmmqr,type:*core.Pod,resource:pods 503ms (15:47:56.393)
Trace[2059295943]:  ---"Txn call completed" 501ms (15:47:56.897)]
Trace[2059295943]: ---"Object stored in database" 501ms (15:47:56.897)
Trace[2059295943]: [503.523354ms] [503.523354ms] END
I0910 15:48:19.448026       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0910 15:48:49.236579       1 trace.go:236] Trace[2058503761]: "Update" accept:application/json, */*,audit-id:bcc632dc-2a29-46f0-a7b4-ad2e9126442a,client:192.168.49.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (10-Sep-2025 15:48:48.607) (total time: 628ms):
Trace[2058503761]: ["GuaranteedUpdate etcd3" audit-id:bcc632dc-2a29-46f0-a7b4-ad2e9126442a,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 628ms (15:48:48.608)
Trace[2058503761]:  ---"Txn call completed" 627ms (15:48:49.236)]
Trace[2058503761]: [628.673659ms] [628.673659ms] END
I0910 15:49:19.447017       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager

* 
* ==> kube-apiserver [1b66d653ccac] <==
* I0822 17:07:21.035618       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:07:21.035962       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:07:21.304672       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:08:20.904546       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:09:20.903929       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:10:20.904318       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:11:20.904638       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:12:20.904321       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:12:21.035637       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:12:21.038615       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:12:21.323053       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:13:20.903922       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:14:20.904474       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:15:20.904282       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:16:20.903859       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:17:20.896655       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:17:21.038780       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:17:21.039007       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:17:21.318588       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:18:20.903601       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:19:20.897664       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:20:20.904284       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:21:20.903660       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:22:20.898705       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:22:21.036729       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:22:21.039225       1 handler.go:232] Adding GroupVersion argoproj.io v1alpha1 to ResourceManager
I0822 17:22:21.334359       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:23:20.896702       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:24:00.597357       1 trace.go:236] Trace[958208827]: "Update" accept:application/json, */*,audit-id:5e0f7e3c-c43a-4d2c-a28d-46de60c556ff,client:192.168.49.2,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (22-Aug-2025 17:23:59.971) (total time: 626ms):
Trace[958208827]: ["GuaranteedUpdate etcd3" audit-id:5e0f7e3c-c43a-4d2c-a28d-46de60c556ff,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 626ms (17:23:59.971)
Trace[958208827]:  ---"Txn call completed" 625ms (17:24:00.597)]
Trace[958208827]: [626.247807ms] [626.247807ms] END
I0822 17:24:20.903460       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:25:20.904028       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:26:20.905190       1 handler.go:232] Adding GroupVersion metrics.k8s.io v1beta1 to ResourceManager
I0822 17:27:01.105336       1 controller.go:128] Shutting down kubernetes service endpoint reconciler
E0822 17:27:02.610832       1 writers.go:122] apiserver was unable to write a JSON response: http: Handler timeout
E0822 17:27:02.610882       1 status.go:71] apiserver received an error that is not an metav1.Status: &errors.errorString{s:"http: Handler timeout"}: http: Handler timeout
E0822 17:27:02.612910       1 writers.go:135] apiserver was unable to write a fallback JSON response: http: Handler timeout
I0822 17:27:02.613084       1 trace.go:236] Trace[637969255]: "Update" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:c8b5da91-afc1-4f8b-9a79-b594df641b0b,client:192.168.49.2,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PUT (22-Aug-2025 17:27:01.172) (total time: 1440ms):
Trace[637969255]: ["GuaranteedUpdate etcd3" audit-id:c8b5da91-afc1-4f8b-9a79-b594df641b0b,key:/leases/kube-node-lease/minikube,type:*coordination.Lease,resource:leases.coordination.k8s.io 1439ms (17:27:01.173)
Trace[637969255]:  ---"Txn call failed" err:context canceled 1375ms (17:27:02.548)]
Trace[637969255]: [1.440301471s] [1.440301471s] END
E0822 17:27:02.648095       1 timeout.go:142] post-timeout activity - time-elapsed: 64.836803ms, PUT "/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube" result: <nil>
E0822 17:27:02.648097       1 finisher.go:175] FinishRequest: post-timeout activity - time-elapsed: 11.325¬µs, panicked: false, err: context canceled, panic-reason: <nil>
E0822 17:27:02.648312       1 finisher.go:175] FinishRequest: post-timeout activity - time-elapsed: 3.308¬µs, panicked: false, err: context canceled, panic-reason: <nil>
E0822 17:27:02.946959       1 writers.go:122] apiserver was unable to write a JSON response: http: Handler timeout
E0822 17:27:02.946996       1 status.go:71] apiserver received an error that is not an metav1.Status: &errors.errorString{s:"http: Handler timeout"}: http: Handler timeout
E0822 17:27:02.948116       1 writers.go:135] apiserver was unable to write a fallback JSON response: http: Handler timeout
I0822 17:27:02.948157       1 trace.go:236] Trace[654652181]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:f17bc78b-8cc4-4aa9-ab10-bd2a18d2e751,client:192.168.49.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events/metrics-server-7c66d45ddc-xvkxw.185e1904c19746ee,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PATCH (22-Aug-2025 17:27:01.971) (total time: 976ms):
Trace[654652181]: ["GuaranteedUpdate etcd3" audit-id:f17bc78b-8cc4-4aa9-ab10-bd2a18d2e751,key:/events/kube-system/metrics-server-7c66d45ddc-xvkxw.185e1904c19746ee,type:*core.Event,resource:events 976ms (17:27:01.971)]
Trace[654652181]: [976.540748ms] [976.540748ms] END
E0822 17:27:02.948249       1 timeout.go:142] post-timeout activity - time-elapsed: 399.425765ms, PATCH "/api/v1/namespaces/kube-system/events/metrics-server-7c66d45ddc-xvkxw.185e1904c19746ee" result: <nil>
I0822 17:27:03.436386       1 trace.go:236] Trace[1786084322]: "Get" accept:application/json, */*,audit-id:34752fb3-a7cb-407f-8a1a-b2d5961b3c35,client:10.244.0.54,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/ingress-nginx/leases/ingress-nginx-leader,user-agent:nginx-ingress-controller/v1.9.4 (linux/amd64) ingress-nginx/846d251814a09d8a5d8d28e2e604bfc7749bcb49,verb:GET (22-Aug-2025 17:27:02.521) (total time: 914ms):
Trace[1786084322]: ---"About to write a response" 914ms (17:27:03.436)
Trace[1786084322]: [914.390345ms] [914.390345ms] END
E0822 17:27:03.437911       1 timeout.go:142] post-timeout activity - time-elapsed: 889.12393ms, GET "/readyz" result: <nil>
I0822 17:27:03.437975       1 trace.go:236] Trace[873915427]: "List" accept:application/json, */*,audit-id:93b9df55-26f0-4519-9211-a5c359392dff,client:10.244.0.54,protocol:HTTP/2.0,resource:pods,scope:namespace,url:/api/v1/namespaces/ingress-nginx/pods,user-agent:nginx-ingress-controller/v1.9.4 (linux/amd64) ingress-nginx/846d251814a09d8a5d8d28e2e604bfc7749bcb49,verb:LIST (22-Aug-2025 17:27:02.522) (total time: 915ms):
Trace[873915427]: ["List(recursive=true) etcd3" audit-id:93b9df55-26f0-4519-9211-a5c359392dff,key:/pods/ingress-nginx,resourceVersion:,resourceVersionMatch:,limit:0,continue: 915ms (17:27:02.522)]
Trace[873915427]: [915.905278ms] [915.905278ms] END

* 
* ==> kube-controller-manager [917f3f68dddc] <==
* I0910 15:40:53.511565       1 event.go:307] "Event occurred" object="default/web-d-8666fdb685" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: web-d-8666fdb685-pbhkj"
I0910 15:40:53.560521       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="791.073276ms"
I0910 15:40:53.949326       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="388.700248ms"
I0910 15:40:53.950332       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="110.287¬µs"
I0910 15:40:54.415809       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="150.52¬µs"
I0910 15:41:02.829287       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="1.098711ms"
I0910 15:41:13.923325       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="137.884¬µs"
I0910 15:41:16.527051       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="136.482¬µs"
I0910 15:41:27.534383       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="90.444¬µs"
I0910 15:41:28.944088       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="87.883¬µs"
I0910 15:41:42.253339       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="99.703¬µs"
I0910 15:43:59.136148       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="21.594¬µs"
I0910 15:43:59.386138       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="16.609¬µs"
I0910 15:44:08.004445       1 event.go:307] "Event occurred" object="default/web-d" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set web-d-8666fdb685 to 2"
I0910 15:44:08.719869       1 event.go:307] "Event occurred" object="default/web-d-8666fdb685" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: web-d-8666fdb685-ch7rv"
I0910 15:44:09.059491       1 event.go:307] "Event occurred" object="default/web-d-8666fdb685" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: web-d-8666fdb685-nqfmp"
I0910 15:44:09.369098       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="1.366569134s"
I0910 15:44:09.807430       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="437.135508ms"
I0910 15:44:09.807641       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="99.663¬µs"
I0910 15:44:14.364310       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="38.691¬µs"
I0910 15:44:14.741687       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="146.799¬µs"
I0910 15:44:22.084919       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="172.967¬µs"
I0910 15:44:22.370677       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="83.016¬µs"
I0910 15:44:22.501901       1 endpointslice_controller.go:310] "Error syncing endpoint slices for service, retrying" key="default/web-svc" err="EndpointSlice informer cache is out of date"
I0910 15:45:08.258827       1 event.go:307] "Event occurred" object="default/web-d" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set web-d-55bd745fcd to 1"
I0910 15:45:08.500880       1 event.go:307] "Event occurred" object="default/web-d-55bd745fcd" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: web-d-55bd745fcd-dvssk"
I0910 15:45:08.607444       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="347.40137ms"
I0910 15:45:08.781100       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="173.563338ms"
I0910 15:45:08.781226       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="64.234¬µs"
I0910 15:45:08.781361       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="87.212¬µs"
I0910 15:45:14.192077       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="38.637¬µs"
I0910 15:45:28.508020       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="240.184¬µs"
I0910 15:45:37.473093       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="5.712¬µs"
I0910 15:45:37.499370       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-8666fdb685" duration="5.968¬µs"
I0910 15:45:43.746386       1 event.go:307] "Event occurred" object="default/web-d" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set web-d-55bd745fcd to 2"
I0910 15:45:43.900282       1 event.go:307] "Event occurred" object="default/web-d-55bd745fcd" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: web-d-55bd745fcd-69bvt"
I0910 15:45:44.047735       1 event.go:307] "Event occurred" object="default/web-d-55bd745fcd" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: web-d-55bd745fcd-dmmqr"
I0910 15:45:44.123264       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="379.777038ms"
I0910 15:45:44.220966       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="97.610425ms"
I0910 15:45:44.221069       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="62.46¬µs"
I0910 15:45:44.287059       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="94.846¬µs"
I0910 15:45:50.659980       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="49.625¬µs"
I0910 15:45:52.733247       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="41.254¬µs"
I0910 15:46:02.507726       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="52.55¬µs"
I0910 15:46:05.642528       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="88.593¬µs"
I0910 15:46:19.522024       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="92.894¬µs"
I0910 15:46:20.456570       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="39.514¬µs"
I0910 15:46:30.481285       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="47.095¬µs"
I0910 15:46:34.690624       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="193.283¬µs"
I0910 15:46:46.551637       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="58.862¬µs"
I0910 15:46:52.422876       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="71.237¬µs"
I0910 15:46:58.501224       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="60.189¬µs"
I0910 15:47:05.458462       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="75.255¬µs"
I0910 15:47:41.451777       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="72.183¬µs"
I0910 15:47:44.512558       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="95.315¬µs"
I0910 15:47:54.460015       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="102.993¬µs"
I0910 15:47:56.897693       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="42.074¬µs"
I0910 15:49:09.498020       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="130.735¬µs"
I0910 15:49:15.427160       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="84.445¬µs"
I0910 15:49:23.554565       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/web-d-55bd745fcd" duration="384.259¬µs"

* 
* ==> kube-controller-manager [d452a80ceeef] <==
* I0910 15:25:11.213897       1 serving.go:348] Generated self-signed cert in-memory
I0910 15:25:12.708068       1 controllermanager.go:189] "Starting" version="v1.28.3"
I0910 15:25:12.708140       1 controllermanager.go:191] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0910 15:25:12.740459       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0910 15:25:12.740962       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0910 15:25:12.743485       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0910 15:25:12.800445       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
E0910 15:25:23.094686       1 controllermanager.go:235] "Error building controller context" err="failed to wait for apiserver being healthy: timed out waiting for the condition: failed to get apiserver /healthz status: an error on the server (\"[+]ping ok\\n[+]log ok\\n[+]etcd ok\\n[+]poststarthook/start-kube-apiserver-admission-initializer ok\\n[+]poststarthook/generic-apiserver-start-informers ok\\n[+]poststarthook/priority-and-fairness-config-consumer ok\\n[+]poststarthook/priority-and-fairness-filter ok\\n[+]poststarthook/storage-object-count-tracker-hook ok\\n[+]poststarthook/start-apiextensions-informers ok\\n[+]poststarthook/start-apiextensions-controllers ok\\n[+]poststarthook/crd-informer-synced ok\\n[+]poststarthook/start-service-ip-repair-controllers ok\\n[-]poststarthook/rbac/bootstrap-roles failed: reason withheld\\n[+]poststarthook/scheduling/bootstrap-system-priority-classes ok\\n[+]poststarthook/priority-and-fairness-config-producer ok\\n[+]poststarthook/start-system-namespaces-controller ok\\n[+]poststarthook/bootstrap-controller ok\\n[+]poststarthook/start-cluster-authentication-info-controller ok\\n[+]poststarthook/start-kube-apiserver-identity-lease-controller ok\\n[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok\\n[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok\\n[+]poststarthook/start-legacy-token-tracking-controller ok\\n[+]poststarthook/aggregator-reload-proxy-client-cert ok\\n[+]poststarthook/start-kube-aggregator-informers ok\\n[+]poststarthook/apiservice-registration-controller ok\\n[+]poststarthook/apiservice-status-available-controller ok\\n[+]poststarthook/kube-apiserver-autoregistration ok\\n[+]autoregister-completion ok\\n[+]poststarthook/apiservice-openapi-controller ok\\n[+]poststarthook/apiservice-openapiv3-controller ok\\n[+]poststarthook/apiservice-discovery-controller ok\\nhealthz check failed\") has prevented the request from succeeding"

* 
* ==> kube-proxy [d466475bcc65] <==
* I0910 15:28:06.306726       1 server_others.go:69] "Using iptables proxy"
I0910 15:28:13.608563       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0910 15:28:20.116672       1 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0910 15:28:20.121111       1 server_others.go:152] "Using iptables Proxier"
I0910 15:28:20.121162       1 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0910 15:28:20.121177       1 server_others.go:438] "Defaulting to no-op detect-local"
I0910 15:28:20.121211       1 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0910 15:28:20.121503       1 server.go:846] "Version info" version="v1.28.3"
I0910 15:28:20.121579       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0910 15:28:20.664323       1 config.go:97] "Starting endpoint slice config controller"
I0910 15:28:20.664361       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0910 15:28:20.664364       1 config.go:188] "Starting service config controller"
I0910 15:28:20.664390       1 shared_informer.go:311] Waiting for caches to sync for service config
I0910 15:28:20.664434       1 config.go:315] "Starting node config controller"
I0910 15:28:20.664571       1 shared_informer.go:311] Waiting for caches to sync for node config
I0910 15:28:21.047341       1 shared_informer.go:318] Caches are synced for node config
I0910 15:28:21.056680       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0910 15:28:21.523773       1 shared_informer.go:318] Caches are synced for service config
I0910 15:28:24.735368       1 trace.go:236] Trace[1755744646]: "iptables save" (10-Sep-2025 15:28:22.182) (total time: 2553ms):
Trace[1755744646]: [2.553003806s] [2.553003806s] END

* 
* ==> kube-scheduler [04faedbf8d59] <==
* E0910 15:25:00.292204       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:00.382312       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:00.382404       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:00.413114       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:00.413157       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:00.530241       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:00.530350       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:00.563243       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:00.563326       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:00.760876       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:00.760965       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:00.905738       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:00.905770       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:01.063399       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:01.063444       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:03.708560       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:03.708647       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:03.780926       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:03.781112       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:03.941996       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:03.942036       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:04.050082       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:04.050170       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:04.283641       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:04.283732       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:04.544570       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:04.544599       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:04.646901       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:04.646984       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:05.111201       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:05.111291       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:05.289594       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:05.289679       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:05.987995       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:05.988081       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:06.029425       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:06.029468       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:06.181661       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:06.181743       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:06.250636       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:06.250680       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:06.860513       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:06.860592       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:07.166010       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:07.166104       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:11.546066       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:11.546145       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:11.780668       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0910 15:25:11.780753       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0910 15:25:19.723103       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0910 15:25:19.723754       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0910 15:25:19.912117       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found]
E0910 15:25:19.912155       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found]
W0910 15:25:19.912174       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found]
E0910 15:25:19.912182       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope: RBAC: [clusterrole.rbac.authorization.k8s.io "system:discovery" not found, clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found, clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found, clusterrole.rbac.authorization.k8s.io "system:basic-user" not found, clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found]
I0910 15:25:33.630925       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0910 15:34:37.570339       1 trace.go:236] Trace[1302358091]: "Scheduling" namespace:default,name:web-d-55bd745fcd-vt6b9 (10-Sep-2025 15:34:36.394) (total time: 792ms):
Trace[1302358091]: ---"Snapshotting scheduler cache and node infos done" 460ms (15:34:36.855)
Trace[1302358091]: ---"Computing predicates done" 331ms (15:34:37.186)
Trace[1302358091]: [792.242078ms] [792.242078ms] END

* 
* ==> kube-scheduler [7229096552db] <==
* E0822 13:12:13.014923       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.038442       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.038474       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.040305       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.040409       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.198215       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.198249       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.385941       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.386028       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.775502       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.775541       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.855493       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.855575       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.946187       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.946243       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:13.956686       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:13.956725       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:14.020543       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:14.020623       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:14.181197       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:14.181255       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:14.465471       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:14.465552       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:14.502685       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:14.502805       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:16.600713       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:16.600752       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:16.800898       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:16.800979       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:17.417091       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:17.417144       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:17.422392       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:17.422425       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:17.514397       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:17.514439       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:17.515571       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0822 13:12:17.515587       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0822 13:12:20.968666       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0822 13:12:20.968699       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0822 13:12:20.968826       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0822 13:12:20.968837       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0822 13:12:20.968882       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0822 13:12:20.968891       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0822 13:12:20.969123       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0822 13:12:20.969179       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0822 13:12:20.969128       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0822 13:12:20.969267       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0822 13:12:20.969286       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0822 13:12:20.969302       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0822 13:12:20.969187       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0822 13:12:20.969352       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0822 13:12:20.969403       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0822 13:12:20.969498       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0822 13:12:20.970365       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0822 13:12:20.970391       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
I0822 13:12:28.916893       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0822 17:27:02.016983       1 secure_serving.go:258] Stopped listening on 127.0.0.1:10259
I0822 17:27:02.019143       1 tlsconfig.go:255] "Shutting down DynamicServingCertificateController"
I0822 17:27:02.080418       1 configmap_cafile_content.go:223] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
E0822 17:27:02.868657       1 run.go:74] "command failed" err="finished without leader elect"

* 
* ==> kubelet <==
* Sep 10 15:45:50 minikube kubelet[1369]: E0910 15:45:50.597293    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:45:51 minikube kubelet[1369]: E0910 15:45:51.915883    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:45:51 minikube kubelet[1369]: E0910 15:45:51.915952    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:45:51 minikube kubelet[1369]: E0910 15:45:51.916085    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c2z5z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-69bvt_default(4d92f546-8054-43db-b52a-1d2c890ce9ec): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:45:51 minikube kubelet[1369]: E0910 15:45:51.916161    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:45:52 minikube kubelet[1369]: E0910 15:45:52.653724    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:46:05 minikube kubelet[1369]: E0910 15:46:05.139726    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:05 minikube kubelet[1369]: E0910 15:46:05.139764    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:05 minikube kubelet[1369]: E0910 15:46:05.139848    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2s2j2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-dmmqr_default(16ca7ebc-e7b5-4571-a2ba-88520ed80e91): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:46:05 minikube kubelet[1369]: E0910 15:46:05.139884    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:46:07 minikube kubelet[1369]: E0910 15:46:07.998485    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:07 minikube kubelet[1369]: E0910 15:46:07.998560    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:07 minikube kubelet[1369]: E0910 15:46:07.998689    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c2z5z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-69bvt_default(4d92f546-8054-43db-b52a-1d2c890ce9ec): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:46:07 minikube kubelet[1369]: E0910 15:46:07.998758    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:46:19 minikube kubelet[1369]: E0910 15:46:19.392933    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:46:20 minikube kubelet[1369]: E0910 15:46:20.394309    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:46:33 minikube kubelet[1369]: E0910 15:46:33.622719    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:33 minikube kubelet[1369]: E0910 15:46:33.622836    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:33 minikube kubelet[1369]: E0910 15:46:33.623010    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c2z5z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-69bvt_default(4d92f546-8054-43db-b52a-1d2c890ce9ec): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:46:33 minikube kubelet[1369]: E0910 15:46:33.623111    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:46:37 minikube kubelet[1369]: E0910 15:46:37.896459    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:37 minikube kubelet[1369]: E0910 15:46:37.896501    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:46:37 minikube kubelet[1369]: E0910 15:46:37.896559    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2s2j2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-dmmqr_default(16ca7ebc-e7b5-4571-a2ba-88520ed80e91): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:46:37 minikube kubelet[1369]: E0910 15:46:37.896593    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:46:46 minikube kubelet[1369]: E0910 15:46:46.393064    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:46:52 minikube kubelet[1369]: E0910 15:46:52.391711    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:46:58 minikube kubelet[1369]: E0910 15:46:58.394197    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:47:05 minikube kubelet[1369]: E0910 15:47:05.392728    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:47:13 minikube kubelet[1369]: E0910 15:47:13.392705    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:47:17 minikube kubelet[1369]: E0910 15:47:17.389705    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:47:30 minikube kubelet[1369]: E0910 15:47:30.360751    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:47:30 minikube kubelet[1369]: E0910 15:47:30.360794    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:47:30 minikube kubelet[1369]: E0910 15:47:30.360941    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c2z5z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-69bvt_default(4d92f546-8054-43db-b52a-1d2c890ce9ec): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:47:30 minikube kubelet[1369]: E0910 15:47:30.360985    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:47:32 minikube kubelet[1369]: E0910 15:47:32.793935    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:47:32 minikube kubelet[1369]: E0910 15:47:32.793981    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:47:32 minikube kubelet[1369]: E0910 15:47:32.794061    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2s2j2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-dmmqr_default(16ca7ebc-e7b5-4571-a2ba-88520ed80e91): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:47:32 minikube kubelet[1369]: E0910 15:47:32.794100    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:47:41 minikube kubelet[1369]: E0910 15:47:41.392328    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:47:44 minikube kubelet[1369]: E0910 15:47:44.394687    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:47:54 minikube kubelet[1369]: E0910 15:47:54.392884    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:47:56 minikube kubelet[1369]: E0910 15:47:56.389586    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:48:08 minikube kubelet[1369]: E0910 15:48:08.394233    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:48:09 minikube kubelet[1369]: E0910 15:48:09.392880    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:48:23 minikube kubelet[1369]: E0910 15:48:23.392762    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:48:24 minikube kubelet[1369]: E0910 15:48:24.392353    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:48:37 minikube kubelet[1369]: E0910 15:48:37.392409    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:48:38 minikube kubelet[1369]: E0910 15:48:38.394007    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:48:50 minikube kubelet[1369]: E0910 15:48:50.392523    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:48:55 minikube kubelet[1369]: E0910 15:48:55.123754    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:48:55 minikube kubelet[1369]: E0910 15:48:55.123831    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:48:55 minikube kubelet[1369]: E0910 15:48:55.123929    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c2z5z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-69bvt_default(4d92f546-8054-43db-b52a-1d2c890ce9ec): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:48:55 minikube kubelet[1369]: E0910 15:48:55.123980    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:49:03 minikube kubelet[1369]: E0910 15:49:03.515366    1369 remote_image.go:180] "PullImage from image service failed" err="rpc error: code = Unknown desc = Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:49:03 minikube kubelet[1369]: E0910 15:49:03.515447    1369 kuberuntime_image.go:53] "Failed to pull image" err="Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied" image="practica:v1.0.0"
Sep 10 15:49:03 minikube kubelet[1369]: E0910 15:49:03.515595    1369 kuberuntime_manager.go:1256] container &Container{Name:apache,Image:practica:v1.0.0,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2s2j2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,} start failed in pod web-d-55bd745fcd-dmmqr_default(16ca7ebc-e7b5-4571-a2ba-88520ed80e91): ErrImagePull: Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
Sep 10 15:49:03 minikube kubelet[1369]: E0910 15:49:03.515681    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ErrImagePull: \"Error response from daemon: pull access denied for practica, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:49:09 minikube kubelet[1369]: E0910 15:49:09.394184    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"
Sep 10 15:49:15 minikube kubelet[1369]: E0910 15:49:15.389645    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-dmmqr" podUID="16ca7ebc-e7b5-4571-a2ba-88520ed80e91"
Sep 10 15:49:23 minikube kubelet[1369]: E0910 15:49:23.393119    1369 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"apache\" with ImagePullBackOff: \"Back-off pulling image \\\"practica:v1.0.0\\\"\"" pod="default/web-d-55bd745fcd-69bvt" podUID="4d92f546-8054-43db-b52a-1d2c890ce9ec"

* 
* ==> kubernetes-dashboard [ba6396ef0d70] <==
* 2025/09/10 15:30:07 Starting overwatch
2025/09/10 15:30:07 Using namespace: kubernetes-dashboard
2025/09/10 15:30:07 Using in-cluster config to connect to apiserver
2025/09/10 15:30:08 Using secret token for csrf signing
2025/09/10 15:30:08 Initializing csrf token from kubernetes-dashboard-csrf secret
2025/09/10 15:30:09 Empty token. Generating and storing in a secret kubernetes-dashboard-csrf
2025/09/10 15:30:09 Successful initial request to the apiserver, version: v1.28.3
2025/09/10 15:30:09 New synchronizer has been registered: kubernetes-dashboard-key-holder-kubernetes-dashboard. Starting
2025/09/10 15:30:09 Generating JWE encryption key
2025/09/10 15:30:09 Starting secret synchronizer for kubernetes-dashboard-key-holder in namespace kubernetes-dashboard
2025/09/10 15:30:10 Initializing JWE encryption key from synchronized object
2025/09/10 15:30:10 Creating in-cluster Sidecar client
2025/09/10 15:30:10 Serving insecurely on HTTP port: 9090
2025/09/10 15:30:10 Successful request to sidecar

* 
* ==> kubernetes-dashboard [d7dee50f7ea9] <==
* 
* 
* ==> storage-provisioner [dfa0b5bb22f0] <==
* I0910 15:29:12.479185       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0910 15:29:16.033248       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0910 15:29:16.033334       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0910 15:29:34.172208       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0910 15:29:34.337783       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_fcf5a503-ed1f-471c-98bb-548c01c3591d!
I0910 15:29:34.337777       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"6f3f0a14-c32e-471f-99e1-205aa125ebf7", APIVersion:"v1", ResourceVersion:"108378", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_fcf5a503-ed1f-471c-98bb-548c01c3591d became leader
I0910 15:29:35.548079       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_fcf5a503-ed1f-471c-98bb-548c01c3591d!

